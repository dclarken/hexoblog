<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Git基础教程]]></title>
    <url>%2Fhexoblog%2F2017%2F10%2F20%2FGit%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.新建一个仓库添加本地上传服务：现在的情景:你已经在本地创建了一个Git仓库后，又想在GitHub创建一个Git仓库，并且让这两个仓库进行远程同步，这样，GitHub上的仓库既可以作为备份，又可以让其他人通过该仓库来协作，真是一举多得。对于新创建的仓库，从本地做备份到github网站上gitbash的代码段如下： 123456$ echo "# learngit.github.io" &gt;&gt; README.md$ git init$ git add README.md$ git commit -m "first commit"$ git remote add origin git@github.com:dclarken/dai.github.io.git$ git push -u origin master 操作解释： 新建一个README文件； 初始化本地文件得到一个.git的隐藏文件，用于追踪地位； 添加README文件到缓存区； 给刚刚添加的文件记录cmmit信息，便于以后管理，并且通过该操作将缓存区的文件上传到master分支上； 在本地远程建立与github仓库的连接； 利用push将上传到master的文件发布到github网站上； error:src refspec master does not match any 原因：引起该错误的原因是，目录中没有文件，空目录是不能提交上去的 解决方法： 1234$ touch README$ git add README $ git commit -m 'first commit'$ git push origin master 2.本地和远程仓库建立连接之后，如何添加和修改文件：123$ git add "filename" 添加文件到缓存区 ；$ git commit -m "add/update…."给刚刚添加的文件记录cmmit信息；$ git push 利用push将上传到master的文件发布到github网站上； 3.本地删除文件并且同步到仓库上：123$ git rm filename$ git commit -m "remove filename"$ git push 对于新建和删除修改文件的小结：这些操作都需要三个步骤： 修改/删除/新建 添加commit git push上传到github 另外：git pull –rebase 从github上下拉到本地，进行同步工作，加上–rebase可以避免跳入merge commit窗口，从而导致的无用记录,一般来说在网页上直接操作即使没有添加commit也会自动添加，但是为了记录好看还是养成加–rebase的习惯吧聊下git pull –rebasegit status可以查看当前的修改情况git checkout – file 让这个文件回到最近一次git commit或git add时的状态。git reset HEAD file可以把暂存区的修改撤销掉（unstage），重新放回工作区 4.将一个已有的github仓库clone到新创建的learngit以及本地仓库中： 在github上创建项目 使用 git clone git@github.com:dclarken/dclarken.github.io.git克隆到本地 编辑项目 git add “dclarken.github.io/“ git commit -m “clone dclarken.github.io/ “ git push origin master 将本地更改推送到远程master分支。 如果在github的remote上已经有了文件，会出现错误。此时应当先pull一下，即：git pull origin master 5.上传时候的某报错： 1234567To github.com:dclarken/learngit.git ! [rejected] master -&gt; master (non-fast-forward)error: failed to push some refs to 'git@github.com:dclarken/learngit.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 原因：GitHub远程仓库中的README.md文件不在本地仓库中。 解决方案： 12$ git pull --rebase origin master$ git push -u origin master 若此时又出现报错或者在平时也有这种报错： 1Git Cannot rebase: You have unstaged changes. 原因：那说明有修改过的文件 解决方案： 123$ git stash$ git pull --rebase （每次push之前最好这样做一次）$ git push origin master 之后用git stash pop stash 解析： git stash 可用来暂存当前正在进行的工作， 比如想pull 最新代码， 又不想加新commit， 或者另外一种情况，为了fix 一个紧急的bug, 先stash, 使返回到自己上一个commit, 改完bug之后再stash pop, 继续原来的工作。所以以前自己在网页上面直接上传代码时，经常不写commit于是在想要添加本地管理的时候，会出现以上报错。 基础命令： 123$ git stash$ do some work$ git stash pop 6.添加一个文件夹并且上传到github：其实这个和上传文件的原理一样，github支持在上传某个文件夹下的文件的时，将文件夹也上传。所以： 123456$ mkdir CodeCut$ cd CodeCut$ touch test.txt$ git add "test.txt"$ git commit -m " add test.txt"$ git push 资料参考：廖学峰官方网站error: failed to push some refs to ‘git@github.com:error:Cannot pull with rebase]]></content>
      <categories>
        <category>笔记</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Hexo和Github的博客搭建]]></title>
    <url>%2Fhexoblog%2F2017%2F10%2F19%2F%E5%9F%BA%E4%BA%8EHexo%E5%92%8CGithub%E7%9A%84%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[搭建原理github pages github是项目托管网站，列出了项目的源文件，github有一个pages功能，可以自定义主页，用来代替默认的列出源列表的这个页面。所以，github Pages可以被认为是用户编写的、托管在github上的静态网页。对于个人博客的主页页面内容可以位于 master 下。user pages只有一个, project pages可以有多个, 对于个人博客而言, 两种方式都可以.如果用户申请了自己的域名, 还可以使用CNAME文件自定义domain name,这样访问你的域名就自动访问到github上的页面. 用户也可以自定义404页面.HexoHexo是一个快速、简洁并且高效的博客框架。Hexo使用Markdown解析文章，还可以使用期主题生成静态网页 搭建步骤大概可以分为以下几个步骤： 搭建环境准备（包括node.js和git环境，gitHub账户的配置） 安装Hexo 配置Hexo 怎样将Hexo与github page联系起来 怎样发布文章 主题 推荐 主题Next的配置 添加404 公益页面 环境准备配置Node.js安装环境：JavaScript工具，前端架构，编写出可扩展性高的服务器 安装Online documentation shortcuts模块 新打开的窗口中输入cmd，敲击回车，打开命令行界面 查看安装的是否成功1node -v npm -v 配置Git环境:Git工具可以在windows系统中的任意文件下进入命令行界面，可以建立Hexo和Github的连接 安装Online documentation shortcuts模块 查看安装是否成功1git --version github账号的配置 新建一个repository，命名为hexoblog 在settings页面中的Github Pages中开启gh pages功能，记录网址可以用于后续配置安装Hexo 新建一个目录并且创建Hexo文件夹，用于安装Hexo，并在命令行的窗口进入到该目录 命令行输入:安装hexo以及查看是否安装123npm install hexo-cli -gnpm install hexo --savehexo -v Hexo的体验 初始化 1hexo init 安装npm组件 1npm install 生成 1hexo g 开启端口 1hexo s 提示，在浏览器中输入以后网址既可以访问hexo界面1INFO Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop. 将hexo和github相连配置Git个人信息 设置Git的user.name和user.email 12git config --global user.name "Lander"git config --global user.email "dclarken@163.com" 生成秘钥，生成的秘钥要使用需要配置为github上的安全ssh秘钥Git ssh 配置使用 1ssh-keygen -t rsa -C "dclarken@163.com" 配置Deployment 在hexo安装目录下找到根配置文件_config.yml文件，找到Deployment句段1234deploy: type: git repo: repo: git@github.com:dclarken/hexoblog.git branch: master git插件安装 提前安装一个扩展1npm install hexo-deployer-git --save 主题配置以及文章发布Next主题配置使用 安装Next，利用Git工具将下载的主题文件拷贝在themes目录下 12cd your-hexo-sitegit clone https://github.com/iissnan/hexo-theme-next themes/next 启用主题，切换主题一般可以用hexo clean来清空缓存 1theme: next 验证主题，生成端口，访问网址观察是否成功配置 1hexo s –debug 主题设定Next主题设定资料地址 添加文章，添加新的文章在source文件夹下的post文件中，文件名为引号中的字符1hexo new post "article title" 文件格式为markdown格式，初始生成的文件内容如下：123456---title: article titledate: 2017-8-12 11:31:21tags: [随笔,freinds]categories: [随笔]--- 添加标签页面，如果不添加该页面在主题config配置文件中，添加的tags会指向404界面12cd your-hexo-sitehexo new page tags 文件补充为以下格式：添加type字段，comments字段可以关闭评论1234title: 标签date: 2017-8-12 12:39:04type: "tags"comments: false 添加分类页面12cd your-hexo-sitehexo new page categories 文件补充以下格式：1234title: 分类date: 2017-8-12 12:39:04type: "categories"comments: false 搭建过程参考资料：参考文章地址致谢作者]]></content>
      <categories>
        <category>博客</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>npm</tag>
        <tag>hexo</tag>
        <tag>github</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ALB应用程序负载均衡]]></title>
    <url>%2Fhexoblog%2F2017%2F10%2F01%2FALB%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[介绍： 应用程序负载均衡器Application Load Balancer是 Elastic Load Balancing 服务的一个负载均衡选项，在应用程序层运行，支持您在运行于一个或多个 Amazon Elastic Compute Cloud (Amazon EC2) 实例上的多个服务或容器之间基于内容定义路由规则。负载均衡器收到请求后，会按照优先级顺序评估侦听器规则以确定应用哪个规则，然后使用轮询路由算法从目标组中选择一个目标以实施规则操作。可以配置侦听器规则，以根据应用程序流量的内容，将请求路由至不同的目标组。每个目标组的路由都是单独进行的，即使某个目标已在多个目标组中注册。应用程序负载均衡器概述文档：文档资料地址 组成部分： 负载均衡器 充当客户端的单一接触点。可以向您的负载均衡器添加一个或多个侦听器。监听规则可以基于路径和基于主机的，例如，如果一个规则具有路径模式 /img/，此规则会将 /img/picture.jpg 的请求转发给指定目标组，规则是具有主机模式.example.com，此规则将*.example.com的请求转发给指定目标组。 侦听器 使用您配置的协议和端口检查来自客户端的连接请求，并根据您定义的规则将请求转发到一个或多个目标组。每个规则指定一个目标组、条件和优先级。满足条件时，流量会转发到目标组。您必须为每个侦听器定义一个默认规则，然后，您可以添加规则来根据请求内容指定不同目标组 (也称为基于内容的路由)。 每个目标组 使用您指定的协议和端口号将请求路由到一个或多个注册目标，例如 EC2 实例。您可以向多个目标组注册一个目标。您可以对每个目标组配置运行状况检查。在注册到目标组 (它是使用负载均衡器的侦听器规则指定的) 的所有目标上，执行运行状况检查。 使用应用程序负载均衡器而不是传统负载均衡器具有以下优势： 支持基于路径的路由。对于根据请求中的 URL 转发请求的侦听器，您可以为它配置规则。这让您可以将应用程序构造为较小的服务，并根据 URL 内容将请求路由到正确的服务。通过使用多个端口注册实例，支持将请求路由到单个 EC2 实例上的多个服务。 支持容器化的应用程序。计划任务时，Amazon EC2 Container Service (Amazon ECS) 可以选择一个未使用的端口，并可以使用此端口向目标组注册该任务。这样可以高效地使用您的群集。 支持单独监控每个服务的运行状况，因为运行状况检查是在目标组级别定义的，并且许多 CloudWatch 指标是在目标组级别报告的。将目标组挂载到 Auto Scaling 组的功能使您能够根据需求动态扩展每个服务。访问日志包含附加信息，并以压缩格式存储。已改进负载均衡器性能]]></content>
      <categories>
        <category>笔记</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>AWS</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[切片解析]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F30%2F%E5%88%87%E7%89%87%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[切片操作符是序列名后跟一个方括号，方括号中有一对可选的数字，并用冒号分割。注意这与你使用的索引操作符十分相似。记住数是可选的，而冒号是必须的。切片操作符中的第一个数（冒号之前）表示切片开始的位置，第二个数（冒号之后）表示切片到哪里结束，第三个数（冒号之后）表示切片间隔数。如果不指定第一个数，Python就从序列首开始。如果没有指定第二个数，则Python会停止在序列尾。注意，返回的序列从开始位置开始 ，刚好在结束位置之前结束。即开始位置是包含在序列切片中的，而结束位置被排斥在切片外。这样，shoplist[1:3]返回从位置1开始，包括位置2，但是停止在位置3的一个序列切片，因此返回一个含有两个项目的切片。类似地，shoplist[:]返回整个序列的拷贝。shoplist[::3]返回位置3，位置6，位置9…的序列切片。你可以用负数做切片。负数用在从序列尾开始计算的位置。例如，shoplist[:-1]会返回除了最后一个项目外包含所有项目的序列切片，shoplist[::-1]会返回倒序序列切片。使用Python解释器交互地尝试不同切片指定组合，即在提示符下你能够马上看到结果。序列的神奇之处在于你可以用相同的方法访问元组、列表和字符串。 参考资料地址多个冒号可以用一个省略号（…）来代替，主要运用与多维数组当中]]></content>
      <categories>
        <category>笔记</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模块-文件管理]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F28%2F%E6%A8%A1%E5%9D%97-%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[文件打开方式：1open(name，[mode[buf]]) name:文件路径 mode:打开方式，w：只写方式，文件不存在则创建文件，文件存在则清空文件不同于a追加模式。 buf:文件缓冲大小 r 只读方式打开 w 只写方式打开 a 追加方式打开 r+/w+ 读写方式打开 a+ 追加和读写方式打开 …b二进制方式打开，例如处理图片信息，省略号表示前面的内容 读取方式： read([size])读取文件，读取size个字节，默认读取全部 readline([size]):读取一行 readlnes([size]):读取完文件，返回每一行所组成的列表 readlines(1)能读取8192个字符数据，读取缓冲buff左右个字节 iter：使用迭代器读取文件，使用迭代器可以实现不消耗大量内存的情况下实现对文件的读取。iter(f)，然后利用for循环读取文件信息。 写入操作： write(str)：写入字符串，写缓存机制，调用close、flush之后才会真正写入 writelines(sequence_of_strings)：写多行到文件Linux缓存取大下可以通过write命令测试出来155648字节 Python文件需要关闭: 1.将写缓存同步到磁盘 2.linux系统中每个进程打开文件的个数是有限的 3.如果打开文件数到了系统限制，在打开文件就会失败 Python文件指针操作：1seek(offset[,whence]): 移动文件指针； offset:偏移量，可以为负数 whence：偏移相对位置（SET、CUR、END）import os os.SEEK_SET:相对文件起始位置 os.SEEK_CUR:相对文件当前位置 os.SEEK_END:相对文件结尾位置 Python文件属性: file.fileno():文件描述符 file.mode():文件打开权限 file.encoding():文件编码格式 标准文件：import sys模块 文件标准输入：sys.stdin 文件标准输出：sys.stdout 文件标准错误：sys.stderr文件命令行参数：sys模块体改sys.argv属性，sys.argv是个字符串组成的列表1open(fname,mode,encoding,..,..) 打开文件可以指定编码方式utf-8格式可以识别中文字符 Python文件处理:import os使用os模块 os.open os.read os.write os.lseek os.access 判断文件的权限：R_OK.W_OK.X_OK listdir(path)返回当前目录下所有文件组成的列表 remove(path)删除文件 rename(old,new)修改文件或者目录名 mkdir(path[,mode])创建目录 mkdirs(path[,mode])创建多级目录 removedirs(path)删除多级目录 rmdir(path)删除目录（目录必须为空目录） os.path.exits(path)当前路径是否存在 .isdir(s)是否是一个目录 .isfile(path)是否是一个文件 .getsize(filename)返回文件大小 .dirname(p)返回路径的目录 .basename(p)返回路径的文件名]]></content>
      <categories>
        <category>笔记</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K8s结合LVS高可用负载均衡与集群外服务访问实践]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F24%2FK8s%E7%BB%93%E5%90%88LVS%E9%AB%98%E5%8F%AF%E7%94%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E4%B8%8E%E9%9B%86%E7%BE%A4%E5%A4%96%E6%9C%8D%E5%8A%A1%E8%AE%BF%E9%97%AE%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[文档资料K8s官方文档翻译 Kubernetes平台Ingress 介绍 Ingress 是一个规则的集合，它允许集群外的流量通过一定的规则到达集群内的 Service 。Ingress三个组件: 反向代理负载均衡器反向代理负载均衡器，即常见的负载均衡软件，如 nginx、Haproxy 等。 Ingress ControllerIngress Controller 与 kubernetes API 进行交互，实时的感知后端 service、pod 等变化， Ingress Controller 再结合下文的 Ingress 生成配置，然后更新反向代理负载均衡器，并刷新其配置，实现动态服务发现与更新。 IngressIngress是规则集合；定义了域名与Kubernetes的service的对应关系;这个规则将与 Ingress Controller 结合， Ingress Controller 将其动态写入到负载均衡器配置中，从而实现整体的服务发现和负载均衡。 TraefikTræfɪk 是一个为了让部署微服务更加便捷而诞生的现代HTTP反向代理、负载均衡工具。 它支持多种后台来自动化、动态的应用它的配置文件设置。特性： 它非常快 无需安装其他依赖，通过Go语言编写的单一可执行文件 支持 Rest API 多种后台支持：Docker, Swarm, Kubernetes, Marathon, Mesos, Consul, Etcd 后台监控, 可以监听后台变化进而自动化应用新的配置文件设置 配置文件热更新。无需重启进程:Traefik 可以与Kubernetes的API进行交互，每当Kubernetes使用Ingress对微服务进行添加、移除、或更新都会被感知，并且可以自动生成它们的配置文件。 指向到你服务的路由将会被直接创建出来。 正常结束http连接 后端断路器 轮询，rebalancer 负载均衡 Rest Metrics 支持最小化 官方 docker 镜像 后台支持SSL 前台支持SSL（包括SNI） 清爽的AngularJS前端页面 支持Websocket 支持HTTP/2 网络错误重试 支持Let’s Encrypt (自动更新HTTPS证书) 高可用集群模式 K8s结合LVS高可用负载均衡与集群外服务访问组网拓扑： 这个案例也可以学习为：如何将四层负载均衡和七层负载均衡相结合来实现对外访问服务。 组网思路如下： 前端为两台LVS服务器，通过keepalive实现负载集群高可用以及虚拟IP，实现外部流量的四层负载，以及作为Kubernetes集群服务访问的入口。LVS负载均衡采用DR模式提高集群的处理速度。 后端三台服务器组成Kubernetes集群，每台节点使用hostPort 的方式部署traefik容器（或者其他能够实现反向代理与负载均衡的服务器如nginx），traefik监听节点的80端口，前端LVS负载均衡监听后端三台Kubernetes节点的80端口将外部访问负载分担至traefik。 然后由Traefik进行七层负载均衡，可以实现基于域名或访问目录等来实现映射与负载，将访问流量映射至Kubernetes Service并通过Service负载至最终业务POD所在的容器。]]></content>
      <categories>
        <category>笔记</category>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K8s集群基本组成]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F19%2FK8s%E9%9B%86%E7%BE%A4%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90%2F</url>
    <content type="text"><![CDATA[K8s集群基本概念Kubernetes 是Google开源的容器集群管理系统，它构建于docker技术之上，基于Docker构建一个容器的调度服务，提供资源调度、均衡容灾、服务注册、动态扩缩容等功能套件，本质上可看作是基于容器技术的mini-PaaS平台。 基本概念：Node:Node也就等同于Mesos集群中的Slave节点，是所有Pod运行所在的工作主机，可以是物理机也可以是虚拟机。不论是物理机还是虚拟机，工作主机的统一特征是上面要运行kubelet管理节点上运行的容器。 Pod:若干相关容器的组合，Pod包含的容器运行在同一host上，这些容器使用相同的网络命令空间、IP地址和端口，相互之间能通过localhost来发现和通信。另外，这些容器还可共享一块存储卷空间。在k8s中创建，调度和管理的最小单位就是Pod，而非容器，Pod通过提供更高层次的抽象，提供了更加灵活的部署和管理模式； k8s的基本操作单元，一个Pod由一个或多个容器组成，通常pod里的容器运行的相同的应用；一个容器相当于一个进程，”一个容器一个进程”的原则，一个pod含有多个容器，就像虚拟机工作时有多个进程在执行操作，POD中的所有容器都是并行启动。结合多个容器集成进单一的Kubernetes节点pod，即容器互联通信。 同一pod包含的容器运行在同一host上，作为统一管理单元：同一pod 共享着相同的volumes， network命名空间， ip和port空间，这是通过 Mapped Container做到的； pid ns：处于同一pod中的应用可以看到彼此的进程 network ns：处于同一pod中的应用可以访问一样的ip和port空间 ipc ns：处于同一pod的应用可以用systemV ipc 或者posix消息队列进行通信 UTC ns：处于同一pod应用共用一个主机名 多容器POD的主要用途是支持主要应用程序的共定位、共管辅助进程。 跨斗容器“帮助”主容器。示例包括日志或数据更改监视程序、监视适配器等。例如，日志监视程序可以由一个团队创建一次，并在不同的应用程序中重用。另一个例子，一个跨斗容器是一个文件或数据装载器，为主容器生成数据。 代理、网桥和适配器将主容器与外部世界连接起来。例如，Apache HTTP服务器或Nginx可以提供静态文件。它还可以充当主容器中Web应用程序的反向代理，以记录和限制HTTP请求。另一个例子是辅助容器，它将请求从主容器路由到外部网络。这使得主容器可以连接到本地主机访问，例如，外部数据库，但不需任何的服务发现。 Pod容器间的通信：Pod介绍 在Kubernetes Pod中共享卷，使用一个共享的Kubernetes卷作为一种简单而有效的方式，在一个POD内容器间进行数据共享。 进程间通信（IPC），一个POD里的容器共享相同的IPC命名空间，这意味着他们也可以互相使用标准进程间通信，如SystemV信号系统或POSIX共享内存。 ReplicationController （RC） RC是用来管理Pod的，每个RC由一个或多个Pod组成；在RC被创建之后，系统将会保持RC中的可用Pod的个数与创建RC时定义的Pod个数一致，如果Pod个数小于定义的个数，RC会启动新的Pod，反之则会杀死多余的Pod。 RC通过定义的Pod模板被创建，创建后对象叫做Pods（也可以理解为RC），可以在线修改Pods的属性，以实现动态缩减、扩展Pods的规模 RC通过label关联对应的Pods，通过修改Pods的label可以删除对应的Pods在需要对Pods中的容器进行更新时，RC采用一个一个替换原则来更新整个Pods中的Pod； reschudeling: 维护pod副本，“多退少补”；即使是某些minion宕机 scaling：通过修改rc的副本数来水平扩展或者缩小运行的pods Rolling updates:一个一个地替换pods来rolling updates服务； multiple release tracks：如果需要在系统中运行multiple release 服务，replication controller使用labels来区分multiple release tracks Label Label是用于区分Pod、Service、RC的key/value键值对 Pod、Service、RC可以有多个label，但是每个label的key只能对应一个value 整个系统都是通过Label进行关联，得到真正需要操作的目标 Service Service也是k8s的最小操作单元，是真实应用服务的抽象 Service通常用来将浮动的资源与后端真实提供服务的容器进行关联 Service对外表现为一个单一的访问接口，外部不需要了解后端的规模与机制 Service是定义在集群中一组运行Pod集合的抽象资源，它提供了所有相同的功能。当一个Service资源被创建后，将会分配一个唯一的IP（也叫做集群IP），这个IP地址将存在于Service的整个生命资源，Service一旦被创建，整个IP无法进行修改。 Pod可以通过Service进行通信，并且所有的通信将会通过Service自动负载均很到所有的Pod中的容器，service是抽象化的pod，为集群提供服务。 目前 kubernetes 共有三种服务暴露的方式:K8s集群外服务访问 LoadBlancer ServiceLoadBlancer Service是kubernetes深度结合云平台的一个组件；当使LoadBlancer Service暴露服务时，实际上是通过向底层云平台申请创建一个负载均衡器来向外暴露服务；目前LoadBlancer Service支持的云平台已经相对完善，比如国外的GCE、DigitalOcean，国内的 阿里云，私有云 OpenStack 等等，由于LoadBlancer Service深度结合了云平台，所以只能在一些云平台上来使用。 NodePort ServiceNodePort Service，实质上就是通过在集群的每个node上暴露一个端口，然后将这个端口映射到某个具体的service来实现的，虽然每个node的端口有很多(默认的取值范围是 30000-32767)，例如：在做反向代理服务器时候，将nginx的80端口映射到30000端口，然后将30000端口暴露，用于做对外服务，但是由于安全性和易用性(服务多了就乱了，还有端口冲突问题)实际使用可能并不多。 IngressIngress可以实现使用nginx等开源的反向代理负载均衡器实现对外暴露服务，可以理解Ingress就是用于配置域名转发，在nginx中就类似upstream，它与ingress-controller结合使用，通过ingress-controller监控到pod及service的变化，动态地将ingress中的转发信息写到诸如nginx、apache、haproxy等组件中实现方向代理和负载均衡。 kubernetes组成 kubectl 客户端命令行工具：将接收的命令，发送给kube-apiserver，作为对整个平台操作的入口。 kube-apiserver REST API服务：作为整个系统的控制入口，以REST API的形式公开，可以横向扩展在高可用的架构中。 kube-controller-manager 多个控制器的合体，用来执行整个系统中的后台任务，多个控制进程的合体： Node Controller 负责整个系统中node up 或down的状态的响应和通知 Replication Controller 负责维持Pods中的正常运行的Pod的个数 Endpoints Controller 负责维持Pods和Service的关联关系 Service Account &amp; Token Controllers负责为新的命名空间创建默认的账号和API访问的Token kube-scheduler 任务调度、命令下发,负责监视新创建的Pods任务，下发至未分配的节点运行该任务 kube-proxy 网络代理转发：kube-proxy运行在每个节点上，负责整个网络规则的连接与转发，使k8s中的service更加抽象化，为Service提供cluster内部的服务发现和负载均衡 kubelet 容器的管理,kubelet运行在每个节点上，作为整个系统的agent，监视着分配到该节点的Pods任务，负责挂载Pods所依赖的卷组，下载Pods的秘钥，运行Pods中的容器（通常是docker），周期获取所有容器的状态，通过导出Pod和节点的状态反馈给REST系统； etcd 信息存储，保存了整个集群的状态 flannel IP地址的分配Cluster，即集群：虚拟机或者物理机的一组集合，运行着Kubernetes ETCD 一个分布式强一致性的key/value存储 可理解为一个存储k8s信息的数据库 Node 工作节点，运行Master节点交付的任务 能运行一个或多个Pods 运行的组件 Kubelet 管理容器的守护进程 管理Docker主机来启动容器的管理程序 定期从etcd获取分配到本机的pod信息，启动或停止容器 接收apiserver的HTTP请求，汇报pod的运行状态 Proxy 服务发现（IP寻址） 定期从etcd获取所有的service根据service信息创建代理 客户pod访问其他pod都经过proxy转发 Master 提供了集群统一视图的中心控制点 一个Master节点来控制多个Node节点 运行的组件 API Server 对操作对象的增删改查 提供RESTful K8s API接口 校验和配置Pod、Service和Replication Controller 统一管理集群系统的入口 Scheduler 资源调度 为新建的pod分配机器 Controller-Manager 容错处理 扩容、缩容 负责执行各种控制器 endpoint-controller定期关联service和pod(关联信息由endpoint对象维护)，保证service到pod的映射总是最新的 replication-controller定期关联replicationController和pod，保证定义的复制数量与实际运行pod的数量总是一致的可操作对象 Pod：k8s上可创建、调度和管理的最小单位，是一个或一组拥有共享卷的容器集 Replication Controller：管理着Pod的生命周期，建议创建Pod都是用rc，他会确保任何时刻Pod的数量都维持在一个特殊设定的值 Service：基本的负载均衡器，为外部某提供一组Pod的一个稳定操作接口 文档资料来自]]></content>
      <categories>
        <category>笔记</category>
        <category>k8s</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dp-求数组连续最大和]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F18%2Fdp-%E6%B1%82%E6%95%B0%E7%BB%84%E8%BF%9E%E7%BB%AD%E6%9C%80%E5%A4%A7%E5%92%8C%2F</url>
    <content type="text"><![CDATA[一个数组有 N 个元素，求连续子数组的最大和。例如：[-1,2,1]，和最大的连续子数组为[2,1]，其和为 3属于动态规划问题，从小到大一直找。 12345678910111213141516#coding:utf8def main(): nums=[int(i) for i in raw_input().split()] #nums=[-1,0,1] print(sum_s(nums))def sum_s(nums): s_max=None s_sum=0 for i in range(len(nums)): if s_sum&gt;0: s_sum=s_sum+nums[i] else: s_sum=nums[i] s_max=max(s_max,s_sum) return s_max main()]]></content>
      <categories>
        <category>code</category>
        <category>dp</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sort用法]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F17%2Fsort%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Python中的sort()方法使用基础文档：格式：12sorted(iterable[, cmp[, key[, reverse]]])iterable.sort(cmp[, key[, reverse]]) 参数解释： iterable指定要排序的list或者iterable，不用多说； cmp为函数，指定排序时进行比较的函数，可以指定一个函数或者lambda函数，如：students为类对象的list，没个成员有三个域，用sorted进行比较时可以自己定cmp函数，例如这里要通过比较第三个数据成员来排序，代码可以这样写： 12students = [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]sorted(students, key=lambda student : student[2]) key为函数，指定取待排序元素的哪一项进行排序，函数用上面的例子来说明，代码如下： 1sorted(students, key=lambda student : student[2]) key指定的lambda函数功能是去元素student的第三个域（即：student[2]），因此sorted排序时，会以students所有元素的第三个域来进行排序。 reverse实现降序排序，需要提供一个布尔值，默认为False（升序排列）。]]></content>
      <categories>
        <category>笔记</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dp-求给定数组中和大于积的次数]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F17%2Fdp-%E6%B1%82%E7%BB%99%E5%AE%9A%E6%95%B0%E7%BB%84%E4%B8%AD%E5%92%8C%E5%A4%A7%E4%BA%8E%E7%A7%AF%E7%9A%84%E6%AC%A1%E6%95%B0%2F</url>
    <content type="text"><![CDATA[问题描述一个袋子里面有n个球，每个球上面都有一个号码(拥有相同号码的球是无区别的)。如果一个袋子是幸运的当且仅当所有球的号码的和大于所有球的号码的积。例如：如果袋子里面的球的号码是{1, 1, 2, 3}，这个袋子就是幸运的，因为1 + 1 + 2 + 3 &gt; 1 1 2 * 3你可以适当从袋子里移除一些球(可以移除0个,但是别移除完)，要使移除后的袋子是幸运的。现在让你编程计算一下你可以获得的多少种不同的幸运的袋子。 输入：球号数组输出种类 123456789101112131415161718192021222324252627282930313233343536#-*- coding:utf-8 -*-def isluck(nums): #幸运袋子判断函数 sum=0 mul=1 for i in nums: sum +=i mul *=i if sum&gt;mul: return True else: return False def composite(array,Sum,multiply): #从小到大的规划过程 count=0 for i in xrange(len(array)): if i&gt;0 and array[i]==array[i-1]: continue Sum+=array[i] multiply*=array[i] if Sum&gt;multiply: count+=1+composite(array[i+1:], Sum, multiply) # 当序列中的数值都比较大的时候能够满足要求，那数值小的也更加容易满足 elif array[i]==1: count+=composite(array[i+1:], Sum, multiply) # 1为特殊情况，当为1的时候，和一定一直大于乘积，所以需要累加 else: break Sum-=array[i] #如果不满足，回退为上一状态 multiply/=array[i] return countdef main(): n=raw_input() array=raw_input().split() array=[int(i) for i in array] array.sort() #首先对其从小到大排列 print composite(array,0,1)main()]]></content>
      <categories>
        <category>code</category>
        <category>dp</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dp-求两个字符串的最大公共子序列]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F16%2Fdp-%E6%B1%82%E4%B8%A4%E4%B8%AA%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E6%9C%80%E5%A4%A7%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[123from __future__ import print_function #将python3中的print函数调用，可以实现end=‘’不换行输出的功能import math 问题描述：求出两个字符串最大公共子序列以及输出他的长度，基础动态规划题目 输入：2017 11 0202 11 2017输出：最大公共子序列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#_*_coding: utf_8 _*_ def lcs(a,b): lena=len(a) lenb=len(b) c=[[0 for i in range(lenb+1)] for j in range(lena+1)] flag=[[0 for i in range(lenb+1)] for j in range(lena+1)] for i in range(lena): for j in range(lenb): if a[i]==b[j]: c[i+1][j+1]=c[i][j]+1 flag[i+1][j+1]='ok' elif c[i+1][j]&gt;c[i][j+1]: c[i+1][j+1]=c[i+1][j] flag[i+1][j+1]='le' else: c[i+1][j+1]=c[i][j+1] flag[i+1][j+1]='up' maxnum=0 for i in range(1,lena): for j in range(lenb): if flag[-i][-j]=='ok': count=c[-i][-j] maxnum=max(maxnum,int(count)) break return c,flag,maxnumdef printLcs(flag,a,i,j): if i==0 or j==0: return if flag[i][j]=='ok': printLcs(flag,a,i-1,j-1) print(a[i-1],end='') elif flag[i][j]=='le': printLcs(flag,a,i,j-1) else: printLcs(flag,a,i-1,j) a='2017 11 02'b='02 11 2017'c,flag,count=lcs(a,b)for i in c: print(i)print('')for j in flag: print(j)print('')printLcs(flag,a,len(a),len(b))print('')print(count)]]></content>
      <categories>
        <category>code</category>
        <category>dp</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>dp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu下安装dockers]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F14%2Fubuntu%E4%B8%8B%E5%AE%89%E8%A3%85dockers%2F</url>
    <content type="text"><![CDATA[安装文档资料dockers安装troubleshooting资料内核变更docker再Linux的kernel3.8上运行最佳。利用 uname -r命令查看当前系统版本的内核，内核版本不满足要求，升级内核：12sudo apt-get install linux-image-generic-lts-raring linux-headers-generic-lts-raringsudo apt-get install --install-recommends linux-generic-lts-raring xserver-xorg-lts-raring libgl1-mesa-glx-lts-raring~sudo reboot 重启ubuntu 更新apt-get的安装源1root@linuxidc:~# vi /etc/apt/sources.list 是包管理工具 apt 所用的记录软件包仓库位置的配置文件/etc/apt/sources.list 详解删除里面的所有内容，把下面的安装源写入 12345678910deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse 然后更新apt-get，利用apt-get安装docker.io123root@linuxidc:~#apt-get updateroot@linuxidc:~#apt-get install docker.ioroot@linuxidc:~# service docker.io restart或者 service docker start 错误信息●报错1：1FATA[0000] Post http:///var/run/docker.sock/v1.18/images/create?fromImage=wpscanteam%2Fvulnerablewordpress%3Alatest: dial unix /var/run/docker.sock: no such file or directory. Are you trying to connect to a TLS-enabled daemon without TLS? 解决办法：12$ sudo touch /var/run/docker.sock$ sudo docker -d touch命令有两个功能：一是用于把已存在文件的时间标签更新为系统当前的时间（默认方式），它们的数据将原封不动地保留下来；二是用来创建新的空文件。文档资料1~docker -d :Run container in background and print container ID 运行容量并且打印容器ID文档资料2 ●报错2：123456INFO[0000] +job serveapi(unix:///var/run/docker.sock) INFO[0000] Listening for HTTP on unix (/var/run/docker.sock) INFO[0000] +job init_networkdriver() INFO[0000] -job init_networkdriver() = OK (0) WARN[0000] Your kernel does not support cgroup swap limit. FATA[0000] Shutting down daemon due to errors: Error loading docker apparmor profile: fork/exec /sbin/apparmor_parser: no such file 解决办法：1$ sudo apt-get install apparmor Apparmor—Linux内核中的强制访问控制系统，是Linux内核的一个安全模块，AppArmor允许系统管理员将每个程序与一个安全配置文件关联，从而限制程序的功能。简单的说，AppArmor是与SELinux类似的一个访问控制系统，通过它你可以指定程序可以读、写或运行哪些文件，是否可以打开网络端口等。作为对传统Unix的自主访问控制模块的补充，AppArmor提供了强制访问控制机制，它已经被整合到2.6版本的Linux内核中。Apparmor]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker内核知识——AUFS及安全性]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F14%2FDocker%E5%86%85%E6%A0%B8%E7%9F%A5%E8%AF%86%E2%80%94%E2%80%94AUFS%E5%8F%8A%E5%AE%89%E5%85%A8%E6%80%A7%2F</url>
    <content type="text"><![CDATA[关于 AUFS（联合文件系统） 的几个特点： AUFS 是一种联合文件系统，它把若干目录按照顺序和权限 mount 为一个目录并呈现出来 默认情况下，只有第一层（第一个目录）是可写的，其余层是只读的。 增加文件：默认情况下，新增的文件都会被放在最上面的可写层中。 删除文件：因为底下各层都是只读的，当需要删除这些层中的文件时，AUFS 使用 whiteout 机制，它的实现是通过在上层的可写的目录下建立对应的whiteout隐藏文件来实现的。 修改文件：AUFS 利用其 CoW （copy-on-write）特性来修改只读层中的文件。AUFS 工作在文件层面，因此，只要有对只读层中的文件做修改，不管修改数据的量的多少，在第一次修改时，文件都会被拷贝到可写层然后再被修改。 节省空间：AUFS 的 CoW 特性能够允许在多个容器之间共享分层，从而减少物理空间占用。 查找文件：AUFS 的查找性能在层数非常多时会出现下降，层数越多，查找性能越低，因此，在制作 Docker 镜像时要注意层数不要太多。 性能：AUFS 的 CoW 特性在写入大型文件时第一次会出现延迟。 一个Linux 系统之中 所有 Docker 容器都共享主机系统的 bootfs 即 Linux 内核 每个容器有自己的 rootfs，它来自不同的 Linux 发行版的基础镜像，包括 Ubuntu，Debian 和 SUSE 等 在操作系统镜像上面一层层附加应用程序的开源组件的镜像 所有基于一种基础镜像的容器都共享这种 rootfs 安全性: AppArmor, SELinux, GRSEC安全永远是相对的，这里有三个方面可以考虑Docker的安全特性: 由kernel namespaces和cgroups实现的Linux系统固有的安全标准; Docker Deamon的安全接口; Linux本身的安全加固解决方案,类如AppArmor, SELinux; 资料参考：内核知识资料AUFS安全性]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker内核知识——Cgroup控制组]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F14%2FDocker%E5%86%85%E6%A0%B8%E7%9F%A5%E8%AF%86%E2%80%94Cgroup%E6%8E%A7%E5%88%B6%E7%BB%84%2F</url>
    <content type="text"><![CDATA[Linux CgroupDocker 容器使用 linux namespace 来隔离其运行环境，使得容器中的进程看起来就像爱一个独立环境中运行一样。但是，光有运行环境隔离还不够，因为这些进程还是可以不受限制地使用系统资源，比如网络、磁盘、CPU以及内存 等。关于其目的，一方面，是为了防止它占用了太多的资源而影响到其它进程；另一方面，在系统资源耗尽的时候，linux 内核会触发 OOM，这会让一些被杀掉的进程成了无辜的替死鬼。因此，为了让容器中的进程更加可控，Docker 使用 Linux cgroups 来限制容器中的进程允许使用的系统资源。Linux Cgroup 可​​​让​​​您​​​为​​​系​​​统​​​中​​​所​​​运​​​行​​​任​​​务​​​（进​​​程​​​）的​​​用​​​户​​​定​​​义​​​组​​​群​​​分​​​配​​​资​​​源​​​ — 比​​​如​​​ CPU 时​​​间​​​、​​​系​​​统​​​内​​​存​​​、​​​网​​​络​​​带​​​宽​​​或​​​者​​​这​​​些​​​资​​​源​​​的​​​组​​​合​​​。​​​您​​​可​​​以​​​监​​​控​​​您​​​配​​​置​​​的​​​ cgroup，拒​​​绝​​​ cgroup 访​​​问​​​某​​​些​​​资​​​源​​​，甚​​​至​​​在​​​运​​​行​​​的​​​系​​​统​​​中​​​动​​​态​​​配​​​置​​​您​​​的​​​ cgroup。所以，可以将 controll groups 理解为 controller （system resource） （for） （process）groups，也就是是说它以一组进程为目标进行系统资源分配和控制。功能： Resource limitation: 限制资源使用，比如内存使用上限以及文件系统的缓存限制。 Prioritization: 优先级控制，比如：CPU利用和磁盘IO吞吐。 Accounting: 一些审计或一些统计，主要目的是为了计费。 Control: 挂起进程，恢复执行进程。 使​​​用​​​ cgroup，系​​​统​​​管​​​理​​​员​​​可​​​更​​​具​​​体​​​地​​​控​​​制​​​对​​​系​​​统​​​资​​​源​​​的​​​分​​​配​​​、​​​优​​​先​​​顺​​​序​​​、​​​拒​​​绝​​​、​​​管​​​理​​​和​​​监​​​控​​​。​​​可​​​更​​​好​​​地​​​根​​​据​​​任​​​务​​​和​​​用​​​户​​​分​​​配​​​硬​​​件​​​资​​​源​​​，提​​​高​​​总​​​体​​​效​​​率​​​。 在实践中：系统管理员一般会利用CGroup做下面这些事（有点像为某个虚拟机分配资源似的）： 隔离一个进程集合（比如：nginx的所有进程），并限制他们所消费的资源，比如绑定CPU的核。 为这组进程分配其足够使用的内存 为这组进程分配相应的网络带宽和磁盘存储限制 限制访问某些设备（通过设置设备的白名单） 子系统说明cgroups 实现了对资源的配额和度量。cgroups 的使用非常简单，提供类似文件的接口，在 /cgroup目录下新建一个文件夹即可新建一个group，在此文件夹中新建task文件，并将pid写入该文件，即可实现对该进程的资源控制。groups可以限制blkio、cpu、cpuacct、cpuset、devices、freezer、memory、net_cls、ns九大子系统的资源，以下是每个子系统的详细说明： blkio 这个子系统设置限制每个块设备的输入输出控制。例如:磁盘，光盘以及usb等等。 cpu 这个子系统使用调度程序为cgroup任务提供cpu的访问。 cpuacct 产生cgroup任务的cpu资源报告。 cpuset 如果是多核心的cpu，这个子系统会为cgroup任务分配单独的cpu和内存。 devices 允许或拒绝cgroup任务对设备的访问。 freezer 暂停和恢复cgroup任务。 memory 设置每个cgroup的内存限制以及产生内存资源报告。 net_cls 标记每个网络包以供cgroup方便使用。 ns 名称空间子系统。 参考资料]]></content>
      <categories>
        <category>笔记</category>
        <category>docker</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贪心算法饭店招待问题]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F14%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E9%A5%AD%E5%BA%97%E6%8B%9B%E5%BE%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述：某餐馆有n张桌子，每张桌子有一个参数：a 可容纳的最大人数； 有m批客人，每批客人有两个参数:b人数，c预计消费金额。在不允许拼桌的情况下，请实现一个算法选择其中一部分客人，使得总预计消费金额最大 基本思路：桌子序列升序排列，客人按照预定花钱多少降序排序，然后贪心法从钱多的客人开始招呼。在遍历能容得下第i批客人的时候需要二分查找去找否则超时。 输入：3 52 4 21 33 53 75 91 10输出：20 1234567891011121314151617181920212223242526272829303132333435363738394041#coding:utf-8def main(): n,m=[int(i) for i in raw_input().split()] a=[int(i) for i in raw_input().split()] guest=[] for i in range(m): guest.append([int(i) for i in raw_input().split()]) print(func(n,m,a,guest))def func(n,m,a,guest): a.sort() value = 0 count = 0 guest.sort(key=lambda x:x[1], reverse=True) i = 0 j = 0 while i &lt; m: index=search(a,guest[i][0]) if index&gt;0: j = j+1 value +=guest[i][1] del a[index] if j == n: break i=i+1 return valuedef search(nums,target): if target&lt;=nums[0]: return 0 if target&gt;nums[-1]: return -1 l=0 r=len(nums)-1 while (l+1)!=r: mid=(l+r)/2 if target&lt;=nums[mid]: r=mid else: l=mid return rmain()]]></content>
      <categories>
        <category>code</category>
        <category>贪心</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>贪心</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGP的工作原理]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F12%2FBGP%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[在我们使用AWS提供的硬件VPN服务时，可以使用静态和动态的方式构建隧道。静态的是指事先知道对方的公网IP，在两个IP之间写好静态的路由，构建一条加密的隧道动态是指使用BGP协议来自动学习路由。 BGP(Border Gateway Protocol)边界网关协议，TCP 179BGP是一种在自治系统（AS）之间动态交换路由信息的路由协议。一个自治系统的经典定义是在一个管理机构控制之下的一组路由器，它使用IGP和普通度量值向其他自治系统转发报文。在BGP中使用自治系统这个术语是为了强调这样一个事实：一个自治系统的管理对于其他自治系统而言是提供一个统一的内部选路计划，它为那些通过它可以到达的网络提供了一个一致的描述。BGP,边界网关协议，是自主网络系统中网关之间交换器路由信息的协议。边界网关协议常常应用于互联网的网关之间。路由表包含已知路由器的列表、路由器能够达到的地址以及到达每个路由器的路径的跳数。BGP报文的四种类型： 报文Open：打招呼“你好，跟我交个朋友吧！” KeepAlive：我还活着呢，别不理我 Update：有新闻…… Notification：我不跟你玩了! BGP协议中消息的应用通过TCP建立BGP连接时，发送open消息连接建立后，如果有路由需要发送或路由变化时，发送UPDATE消息通告对端路由信息稳定后此时要定时发送KEEPALIVE消息（60s）以保持BGP连接的有效性当本地BGP在运行中发现错误时，要发送NOTIFICATION消息通告BGP对端 BGP择路的13个规则 忽略下一跳不可达的路由 忽略不同步的IBGP路由 首选具有最大权重优先，思科私有。(local to router) 首选具有最大本地优先级优先。(global within AS) 首选具有始发本地的路由的路由器优先，(next hop=0.0.0.0) 首选具有最短AS-PATH的路由。 首选具有最小的源码的路由，IGP〈EBP〈incomplete 当所有路由的AS号都相同的时候，首选MED最低的路由，在所有AS号码相同的时候比较MED 首选具有EBGP〉联盟EBGP&gt;IBGP 首选具有最近的IGP邻居路由器优先，metric 首选具有最老的路由优先（注意：现在这条基本不用） 首选具有最低ROUTER-ID的路由。(2个BGP地址不能建邻) 首选具有最低的neighbor的IP地址]]></content>
      <categories>
        <category>笔记</category>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>网络协议</tag>
        <tag>bgp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vector用法]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F12%2Fvector%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[文档来自vector(向量): C++中的一种数据结构,确切的说是一个类.它相当于一个动态的数组,当程序员无法知道自己需要的数组的规模多大时,用其来解决问题可以达到最大节约空间的目的.文件包含:首先在程序开头处加上#include以包含所需要的类文件vector还有一定要加上using namespace std;变量声明:声明一个int向量以替代一维的数组:vector a;用vector代替二维数组.其实只要声明一个一维数组向量即可,而一个数组的名字其实代表的是它的首地址,所以只要声明一个地址的向量即可,即:vector a.同理想用向量代替三维数组也是一样,vector a;再往上面依此类推.int可以改成其他的如char、string甚至是strcut。具体的用法以及函数调用: 1.push_back 在数组的最后添加一个数据 2.pop_back 去掉数组的最后一个数据 3.at 得到编号位置的数据 4.begin 得到数组头的指针 5.end 得到数组的最后一个单元+1的指针 6．front 得到数组头的引用 7.back 得到数组的最后一个单元的引用 8.max_size 得到vector最大可以是多大 9.capacity 当前vector分配的大小 10.size 当前使用数据的大小 11.resize 改变当前使用数据的大小，如果它比当前使用的大者填充默认值 12.reserve 改变当前vecotr所分配空间的大小 13.erase 删除指针指向的数据项 14.clear 清空当前的vector 15.rbegin 将vector反转后的开始指针返回(其实就是原来的end-1) 16.rend 将vector反转构的结束指针返回(其实就是原来的begin-1) 17.empty 判断vector是否为空 18.swap 与另一个vector交换数据详细的函数实现功能: c.clear() 移除容器中所有数据。 c.empty() 判断容器是否为空。 c.erase(pos) 删除pos位置的数据 c.erase(beg,end) 删除[beg,end]区间的数据 如： vec.erase(vec.begin()+2);删除第3个元素 c.front() 传回第一个数据。 c.insert(pos,elem) 在pos位置插入一个elem拷贝 c.pop_back() 删除最后一个数据。 c.push_back(elem) 在尾部加入一个数据。 c.resize(num) 重新设置该容器的大小 c.size() 回容器中实际数据的个数。 c.begin() 返回指向容器第一个元素的迭代器 c.end() 返回指向容器最后一个元素的迭代器 c1.swap(c2)==swap(c1,c2) 将c1和c2元素互换。两操作相同。 #include&lt;algorithm&gt;中的泛函算法搜索算法：find() 、search() 、count() 、find_if() 、search_if() 、count_if()分类排序：sort() 、merge()删除算法：unique() 、remove()生成和变异：generate() 、fill() 、transformation() 、copy()关系算法：equal() 、min() 、max()1sort(v1.begin(),vi.begin()+v1.size/2）; 对v1的前半段元素排序，默认是从小到大排序，即默认为冒泡排序。1sort(v1.begin(),v1.end()); 对整个vector做排序定义排序比较函数：1234bool cmp(const int &amp;a,const int &amp;b)&#123; return a&gt;b;&#125; 调用时:sort(vec.begin(),vec.end(),cmp)，这样就降序排序。其他功能: c.at(idx) 传回索引idx所指的数据，如果idx越界，抛出out_of_range。 c.back() 传回最后一个数据，不检查这个数据是否存在。 c.front() 传回地一个数据。 get_allocator 使用构造函数返回一个拷贝。 c.rbegin() 传回一个逆向队列的第一个数据。 c.rend() 传回一个逆向队列的最后一个数据的下一个位置。]]></content>
      <categories>
        <category>笔记</category>
        <category>c++</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>数据结构</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux服务器查看性能的几个命令]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F12%2Flinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9F%A5%E7%9C%8B%E6%80%A7%E8%83%BD%E7%9A%84%E5%87%A0%E4%B8%AA%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[一、uptime命令 12$ uptime23:51:26 up 21:31, 1 user, load average: 30.02, 26.43, 19.02 这个命令可以快速查看机器的负载情况。在Linux系统中，这些数据表示等待CPU资源的进程和阻塞在不可中断IO进程（进程状态为D）的数量。这些数据可以让我们对系统资源使用有一个宏观的了解。命令的输出分别表示1分钟、5分钟、15分钟的平均负载情况。通过这三个数据，可以了解服务器负载是在趋于紧张还是趋于缓解。如果1分钟平均负载很高，而15分钟平均负载很低，说明服务器正在命令高负载情况，需要进一步排查CPU资源都消耗在了哪里。反之，如果15分钟平均负载很高，1分钟平均负载较低，则有可能是CPU资源紧张时刻已经过去。上面例子中的输出，可以看见最近1分钟的平均负载非常高，且远高于最近15分钟负载，因此我们需要继续排查当前系统中有什么进程消耗了大量的资源。可以通过下文将会介绍的vmstat、mpstat等命令进一步排查。 二、dmesg命令 1234567$ dmesg | tail[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0[...][1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB[2320864.954447] TCP: Possible SYN flooding on port 7001. Droppingrequest. Check SNMP counters. 该命令会输出系统日志的最后10行。示例中的输出，可以看见一次内核的oom kill和一次TCP丢包。这些日志可以帮助排查性能问题。千万不要忘了这一步。 三、vmstat命令 12345678$ vmstat 1procs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----r b swpd free buff cache si so bi bo in cs us sy id wa st34 0 0 200889792 73708 591828 0 0 0 5 6 10 96 1 3 0 032 0 0 200889920 73708 591860 0 0 0 592 13284 4282 98 1 1 0 032 0 0 200890112 73708 591860 0 0 0 0 9501 2154 99 1 0 0 032 0 0 200889568 73712 591856 0 0 0 48 11900 2459 99 0 0 0 032 0 0 200890208 73712 591860 0 0 0 0 15898 4840 98 1 1 0 0 vmstat(8) 命令，每行会输出一些系统核心指标，这些指标可以让我们更详细的了解系统状态。后面跟的参数1，表示每秒输出一次统计信息，表头提示了每一列的含义，这几介绍一些和性能调优相关的列： r：等待在CPU资源的进程数。这个数据比平均负载更加能够体现CPU负载情况，数据中不包含等待IO的进程。如果这个数值大于机器CPU核数，那么机器的CPU资源已经饱和。 free：系统可用内存数（以千字节为单位），如果剩余内存不足，也会导致系统性能问题。下文介绍到的free命令，可以更详细的了解系统内存的使用情况。 si，so：交换区写入和读取的数量。如果这个数据不为0，说明系统已经在使用交换区（swap），机器物理内存已经不足。 us, sy, id, wa, st：这些都代表了CPU时间的消耗，它们分别表示用户时间（user）、系统（内核）时间（sys）、空闲时间（idle）、IO等待时间（wait）和被偷走的时间（stolen，一般被其他虚拟机消耗）。 上述这些CPU时间，可以让我们很快了解CPU是否出于繁忙状态。一般情况下，如果用户时间和系统时间相加非常大，CPU出于忙于执行指令。如果IO等待时间很长，那么系统的瓶颈可能在磁盘IO。 示例命令的输出可以看见，大量CPU时间消耗在用户态，也就是用户应用程序消耗了CPU时间。这不一定是性能问题，需要结合r队列，一起分析。 四、mpstat命令 123456789$ mpstat -P ALL 1Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU)07:38:49 PM CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle07:38:50 PM all 98.47 0.00 0.75 0.00 0.00 0.00 0.00 0.00 0.00 0.7807:38:50 PM 0 96.04 0.00 2.97 0.00 0.00 0.00 0.00 0.00 0.00 0.9907:38:50 PM 1 97.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 2.0007:38:50 PM 2 98.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 1.0007:38:50 PM 3 96.97 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 3.03[...] 该命令可以显示每个CPU的占用情况，如果有一个CPU占用率特别高，那么有可能是一个单线程应用程序引起的。 五、pidstat命令 1234567891011121314$ pidstat 1Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU)07:41:02 PM UID PID %usr %system %guest %CPU CPU Command07:41:03 PM 0 9 0.00 0.94 0.00 0.94 1 rcuos/007:41:03 PM 0 4214 5.66 5.66 0.00 11.32 15 mesos-slave07:41:03 PM 0 4354 0.94 0.94 0.00 1.89 8 java07:41:03 PM 0 6521 1596.23 1.89 0.00 1598.11 27 java07:41:03 PM 0 6564 1571.70 7.55 0.00 1579.25 28 java07:41:03 PM 60004 60154 0.94 4.72 0.00 5.66 9 pidstat07:41:03 PM UID PID %usr %system %guest %CPU CPU Command07:41:04 PM 0 4214 6.00 2.00 0.00 8.00 15 mesos-slave07:41:04 PM 0 6521 1590.00 1.00 0.00 1591.00 27 java07:41:04 PM 0 6564 1573.00 10.00 0.00 1583.00 28 java07:41:04 PM 108 6718 1.00 0.00 0.00 1.00 0 snmp-pass07:41:04 PM 60004 60154 1.00 4.00 0.00 5.00 9 pidstat pidstat命令输出进程的CPU占用率，该命令会持续输出，并且不会覆盖之前的数据，可以方便观察系统动态。如上的输出，可以看见两个JAVA进程占用了将近1600%的CPU时间，既消耗了大约16个CPU核心的运算资源。 六、iostat命令 123456789101112$ iostat -xz 1Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU)avg-cpu: %user %nice %system %iowait %steal %idle73.96 0.00 3.73 0.03 0.06 22.21Device: rrqm/s wrqm/s r/s w/s rkB/s wkB/s avgrq-sz avgqu-sz await r_await w_await svctm %utilxvda 0.00 0.23 0.21 0.18 4.52 2.08 34.37 0.00 9.98 13.80 5.42 2.44 0.09xvdb 0.01 0.00 1.02 8.94 127.97 598.53 145.79 0.00 0.43 1.78 0.28 0.25 0.25xvdc 0.01 0.00 1.02 8.86 127.79 595.94 146.50 0.00 0.45 1.82 0.30 0.27 0.26dm-0 0.00 0.00 0.69 2.32 10.47 31.69 28.01 0.01 3.23 0.71 3.98 0.13 0.04dm-1 0.00 0.00 0.00 0.94 0.01 3.78 8.00 0.33 345.84 0.04 346.81 0.01 0.00dm-2 0.00 0.00 0.09 0.07 1.35 0.36 22.50 0.00 2.55 0.23 5.62 1.78 0.03[...] iostat命令主要用于查看机器磁盘IO情况。该命令输出的列，主要含义是： r/s, w/s, rkB/s, wkB/s：分别表示每秒读写次数和每秒读写数据量（千字节）。读写量过大，可能会引起性能问题。 await：IO操作的平均等待时间，单位是毫秒。这是应用程序在和磁盘交互时，需要消耗的时间，包括IO等待和实际操作的耗时。如果这个数值过大，可能是硬件设备遇到了瓶颈或者出现故障。 avgqu-sz：向设备发出的请求平均数量。如果这个数值大于1，可能是硬件设备已经饱和（部分前端硬件设备支持并行写入）。 %util：设备利用率。这个数值表示设备的繁忙程度，经验值是如果超过60，可能会影响IO性能（可以参照IO操作平均等待时间）。如果到达100%，说明硬件设备已经饱和。 如果显示的是逻辑设备的数据，那么设备利用率不代表后端实际的硬件设备已经饱和。值得注意的是，即使IO性能不理想，也不一定意味这应用程序性能会不好，可以利用诸如预读取、写缓存等策略提升应用性能。 七、free命令 12345$ free -mtotal used free shared buffers cachedMem: 245998 24545 221453 83 59 541-/+ buffers/cache: 23944 222053Swap: 0 0 0 free命令可以查看系统内存的使用情况，-m参数表示按照兆字节展示。最后两列分别表示用于IO缓存的内存数，和用于文件系统页缓存的内存数。需要注意的是，第二行-/+ buffers/cache，看上去缓存占用了大量内存空间。这是Linux系统的内存使用策略，尽可能的利用内存，如果应用程序需要内存，这部分内存会立即被回收并分配给应用程序。因此，这部分内存一般也被当成是可用内存。如果可用内存非常少，系统可能会动用交换区（如果配置了的话），这样会增加IO开销（可以在iostat命令中提现），降低系统性能。 八、sar命令 12345678910$ sar -n DEV 1Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU)12:16:48 AM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil12:16:49 AM eth0 18763.00 5032.00 20686.42 478.30 0.00 0.00 0.00 0.0012:16:49 AM lo 14.00 14.00 1.36 1.36 0.00 0.00 0.00 0.0012:16:49 AM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.0012:16:49 AM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil12:16:50 AM eth0 19763.00 5101.00 21999.10 482.56 0.00 0.00 0.00 0.0012:16:50 AM lo 20.00 20.00 3.25 3.25 0.00 0.00 0.00 0.0012:16:50 AM docker0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 sar命令在这里可以查看网络设备的吞吐率。在排查性能问题时，可以通过网络设备的吞吐量，判断网络设备是否已经饱和。如示例输出中，eth0网卡设备，吞吐率大概在22 Mbytes/s，既176 Mbits/sec，没有达到1Gbit/sec的硬件上限。sar -n TCP,ETCP 112345678910$ sar -n TCP,ETCP 1Linux 3.13.0-49-generic (titanclusters-xxxxx) 07/14/2015 _x86_64_ (32 CPU)12:17:19 AM active/s passive/s iseg/s oseg/s12:17:20 AM 1.00 0.00 10233.00 18846.0012:17:19 AM atmptf/s estres/s retrans/s isegerr/s orsts/s12:17:20 AM 0.00 0.00 0.00 0.00 0.0012:17:20 AM active/s passive/s iseg/s oseg/s12:17:21 AM 1.00 0.00 8359.00 6039.0012:17:20 AM atmptf/s estres/s retrans/s isegerr/s orsts/s12:17:21 AM 0.00 0.00 0.00 0.00 0.00 sar命令在这里用于查看TCP连接状态，其中包括： active/s：每秒本地发起的TCP连接数，既通过connect调用创建的TCP连接； passive/s：每秒远程发起的TCP连接数，即通过accept调用创建的TCP连接； retrans/s：每秒TCP重传数量； TCP连接数可以用来判断性能问题是否由于建立了过多的连接，进一步可以判断是主动发起的连接，还是被动接受的连接。TCP重传可能是因为网络环境恶劣，或者服务器压 sar命令也可以查看指定pid的信息 1$ sar -x pid 1 1000 九、top命令 123456789101112131415161718$ toptop - 00:15:40 up 21:56, 1 user, load average: 31.09, 29.87, 29.92Tasks: 871 total, 1 running, 868 sleeping, 0 stopped, 2 zombie%Cpu(s): 96.8 us, 0.4 sy, 0.0 ni, 2.7 id, 0.1 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem: 25190241+total, 24921688 used, 22698073+free, 60448 buffersKiB Swap: 0 total, 0 used, 0 free. 554208 cached MemPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND20248 root 20 0 0.227t 0.012t 18748 S 3090 5.2 29812:58 java4213 root 20 0 2722544 64640 44232 S 23.5 0.0 233:35.37 mesos-slave66128 titancl+ 20 0 24344 2332 1172 R 1.0 0.0 0:00.07 top5235 root 20 0 38.227g 547004 49996 S 0.7 0.2 2:02.74 java4299 root 20 0 20.015g 2.682g 16836 S 0.3 1.1 33:14.42 java 1 root 20 0 33620 2920 1496 S 0.0 0.0 0:03.82 init2 root 20 0 0 0 0 S 0.0 0.0 0:00.02 kthreadd3 root 20 0 0 0 0 S 0.0 0.0 0:05.35 ksoftirqd/05 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H6 root 20 0 0 0 0 S 0.0 0.0 0:06.94 kworker/u256:08 root 20 0 0 0 0 S 0.0 0.0 2:38.05 rcu_sched top命令包含了前面好几个命令的检查的内容。比如系统负载情况（uptime）、系统内存使用情况（free）、系统CPU使用情况（vmstat）等。因此通过这个命令，可以相对全面的查看系统负载的来源。同时，top命令支持排序，可以按照不同的列排序，方便查找出诸如内存占用最多的进程、CPU占用率最高的进程等。但是，top命令相对于前面一些命令，输出是一个瞬间值，如果不持续盯着，可能会错过一些线索。这时可能需要暂停top命令刷新，来记录和比对数据。]]></content>
      <categories>
        <category>笔记</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Linux</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[top命令详解]]></title>
    <url>%2Fhexoblog%2F2017%2F09%2F11%2Ftop%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718$ toptop - 00:15:40 up 21:56, 1 user, load average: 31.09, 29.87, 29.92Tasks: 871 total, 1 running, 868 sleeping, 0 stopped, 2 zombie%Cpu(s): 96.8 us, 0.4 sy, 0.0 ni, 2.7 id, 0.1 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem: 25190241+total, 24921688 used, 22698073+free, 60448 buffersKiB Swap: 0 total, 0 used, 0 free. 554208 cached MemPID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND20248 root 20 0 0.227t 0.012t 18748 S 3090 5.2 29812:58 java4213 root 20 0 2722544 64640 44232 S 23.5 0.0 233:35.37 mesos-slave66128 titancl+ 20 0 24344 2332 1172 R 1.0 0.0 0:00.07 top5235 root 20 0 38.227g 547004 49996 S 0.7 0.2 2:02.74 java4299 root 20 0 20.015g 2.682g 16836 S 0.3 1.1 33:14.42 java 1 root 20 0 33620 2920 1496 S 0.0 0.0 0:03.82 init2 root 20 0 0 0 0 S 0.0 0.0 0:00.02 kthreadd3 root 20 0 0 0 0 S 0.0 0.0 0:05.35 ksoftirqd/05 root 0 -20 0 0 0 S 0.0 0.0 0:00.00 kworker/0:0H6 root 20 0 0 0 0 S 0.0 0.0 0:06.94 kworker/u256:08 root 20 0 0 0 0 S 0.0 0.0 2:38.05 rcu_sched 第一行：uptime命令一样 top： 这个没有什么意思，只是个名称而以01：47：56 ： 系统当前时间up 1:26 ： 系统开机到现在经过了多少时间2 users ： 当前2用户在线load average:0.00,0.00,0.00： 系统1分钟、5分钟、15分钟的CPU负载信息 第二行：vmstat Tasks：英文意思是工作;任务;差事。38 total：很好理解，就是当前有38个任务，也就是38个进程。1 running：1个进程正在运行37 sleeping：37个进程睡眠0 stopped：停止的进程数0 zombie：僵死的进程数Cpu(s)：表示这一行显示CPU总体信息0.0%us：用户态进程占用CPU时间百分比，不包含renice值为负的任务占用的CPU的时间。0.7%sy：内核占用CPU时间百分比0.0%ni：renice值为负的任务的用户态进程的CPU时间百分比。nice是优先级的意思99.3%id：空闲CPU时间百分比0.0%wa：等待I/O的CPU时间百分比0.0%hi：CPU硬中断时间百分比0.0%si：CPU软中断时间百分比0.0%st：被偷走的时间 第三行：free Men：内存的意思256412k total：物理内存总量30156k used：使用的物理内存量226256 free：空闲的物理内存量8176k buffers：用作内核缓存的物理内存量Swap：交换空间337356k total：交换区总量0k used：使用的交换区量337356k free：空闲的交换区量12160k cached：缓冲交换区总量 第四行：pidstat PID：进程的IDUSER：进程所有者PR：进程的优先级别，越小越优先被执行NInice：值VIRT：进程占用的虚拟内存RES：进程占用的物理内存SHR：进程使用的共享内存S：进程的状态。S表示休眠，R表示正在运行，Z表示僵死状态，N表示该进程优先值为负数%CPU：进程占用CPU的使用率%MEM：进程使用的物理内存和总内存的百分比TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值。COMMAND：进程启动命令名称 一些常用的linux top命令操作指令： q：退出top命令空格：立即刷新s：设置刷新时间间隔c：显示命令完全模式t:：显示或隐藏进程和CPU状态信息m：显示或隐藏内存状态信息l：显示或隐藏uptime信息f：增加或减少进程显示标志S：累计模式，会把已完成或退出的子进程占用的CPU时间累计到父进程的MITE+P：按%CPU使用率排行T：按MITE+排行M：按%MEM排行u：指定显示用户进程r：修改进程renice值kkill：进程i：只显示正在运行的进程W：保存对top的设置到文件~/.toprc，下次启动将自动调用toprc文件的设置。h：帮助命令。原文]]></content>
      <categories>
        <category>笔记</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Linux</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dijkstra算法]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F23%2FDijkstra%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[文档资料：代码详解算法详解 freopen函数freopen妙用文档资料因为文件指针使用的是标准流文件，因此我们可以不定义文件指针。接下来我们使用freopen()函数以只读方式r(read)打开输入文件slyar.in1freopen("slyar.in", "r", stdin); 然后使用freopen()函数以写入方式w(write)打开输出文件slyar.out1freopen("slyar.out", "w", stdout); 单独使用stdin方法时候，系统有的时候会不读取我们自己创建的文件，这个时候的解决办法可以是写利用stdout输出一个txt的文件，然后将该文件改名并且填入需要输入的内容，作为stdio的文件。 算法步骤： a.初始时，S只包含源点，即S＝{v}，v的距离为0。U包含除v外的其他顶点，即:U={其余顶点}，若v与U中顶点u有边，则正常有权值，若u不是v的出边邻接点，则权值为∞。 b.从U中选取一个距离v最小的顶点k，把k，加入S中（该选定的距离就是v到k的最短路径长度）。 c.以k为新考虑的中间点，修改U中各顶点的距离；若从源点v到顶点u的距离（经过顶点k）比原来距离（不经过顶点k）短，则修改顶点u的距离值，修改后的距离值的顶点k的距离加上边上的权。 d.重复步骤b和c直到所有顶点都包含在S中 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135#include &lt;iostream&gt;#include &lt;stdio.h&gt;#include &lt;fstream&gt;#include &lt;stdlib.h&gt;using namespace std;const int maxnum = 100;const int maxint = 999999;// 各数组都从下标1开始int dist[maxnum]; // 表示当前点到源点的最短路径长度int prev[maxnum]; // 记录当前点的前一个结点int c[maxnum][maxnum]; // 记录图的两点间路径长度int n, line; // 图的结点数和路径数// n -- n nodes// v -- the source node// dist[] -- the distance from the ith node to the source node// prev[] -- the previous node of the ith node// c[][] -- every two nodes' distancevoid Dijkstra(int n, int v, int *dist, int *prev, int c[maxnum][maxnum])&#123; bool s[maxnum]; // 判断是否已存入该点到S集合中 for(int i=1; i&lt;=n; ++i) &#123; dist[i] = c[v][i]; s[i] = 0; // 初始都未用过该点 if(dist[i] == maxint) prev[i] = 0; else prev[i] = v; &#125; dist[v] = 0; s[v] = 1; // 依次将未放入S集合的结点中，取dist[]最小值的结点，放入结合S中 // 一旦S包含了所有V中顶点，dist就记录了从源点到所有其他顶点之间的最短路径长度 // 注意是从第二个节点开始，第一个为源点 for(int i=2; i&lt;=n; ++i) &#123; int tmp = maxint; int u = v; // 找出当前未使用的点j的dist[j]最小值 for(int j=1; j&lt;=n; ++j) if((!s[j]) &amp;&amp; dist[j]&lt;tmp) &#123; u = j; // u保存当前邻接点中距离最小的点的号码 tmp = dist[j]; &#125; s[u] = 1; // 表示u点已存入S集合中 // 更新dist for(int j=1; j&lt;=n; ++j) if((!s[j]) &amp;&amp; c[u][j]&lt;maxint) &#123; int newdist = dist[u] + c[u][j]; if(newdist &lt; dist[j]) &#123; dist[j] = newdist; prev[j] = u; &#125; &#125; &#125;&#125;// 查找从源点v到终点u的路径，并输出void searchPath(int *prev,int v, int u)&#123; int que[maxnum]; int tot = 1; que[tot] = u; tot++; int tmp = prev[u]; while(tmp != v) &#123; que[tot] = tmp; tot++; tmp = prev[tmp]; &#125; que[tot] = v; for(int i=tot; i&gt;=1; --i) if(i != 1) cout &lt;&lt; que[i] &lt;&lt; " -&gt; "; else cout &lt;&lt; que[i] &lt;&lt; endl;&#125;int main()&#123; freopen("input.txt", "r", stdin); if( freopen("input.txt","r",stdin)== NULL ) cout&lt;&lt; "false"&lt;&lt;endl; else cout&lt;&lt; "open"&lt;&lt;endl; // 各数组都从下标1开始 // 输入结点数 cin &gt;&gt; n; // 输入路径数 cin &gt;&gt; line; int p, q, len; // 输入p, q两点及其路径长度 // 初始化c[][]为maxint for(int i=1; i&lt;=n; ++i) for(int j=1; j&lt;=n; ++j) c[i][j] = maxint; for(int i=1; i&lt;=line; ++i) &#123; cin &gt;&gt; p &gt;&gt; q &gt;&gt; len; if(len &lt; c[p][q]) // 有重边 &#123; c[p][q] = len; // p指向q c[q][p] = len; // q指向p，这样表示无向图 &#125; &#125; for(int i=1; i&lt;=n; ++i) dist[i] = maxint; for(int i=1; i&lt;=n; ++i) &#123; for(int j=1; j&lt;=n; ++j) printf("%8d", c[i][j]); printf("\n"); &#125; Dijkstra(n, 1, dist, prev, c); // 最短路径长度 cout &lt;&lt; "源点到最后一个顶点的最短路径长度: " &lt;&lt; dist[n] &lt;&lt; endl; // 路径 cout &lt;&lt; "源点到最后一个顶点的路径为: "; searchPath(prev, 1, n);&#125;]]></content>
      <categories>
        <category>笔记</category>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python语法]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F19%2FPython%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[#基本语法#]]></content>
      <categories>
        <category>笔记</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jdk+eclipse+python环境搭建]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F15%2Fjdk%2Beclipse%2Bpython%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[jdk下载：（java环境配置）jdk下载地址环境变量配置首先设置JAVA_HOME,点击新建，变量名：JAVA_HOME,变量值：D:\java\jdk1.7.0,即jdk安装的路径。设置CLASSPATH属性，变量名：CLASSPATH，变量值：.;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar;此时需要注意的是最前有.;，不能忘记，%JAVA_HOME%代表D:\java\jdk1.7.0此路径。设置path属性，变量名：path，变量值：%java_home%\bin;%java_home%\jre\bin;，此属性一般都是有的，只需添加即可，注意分号的问题。在cmd中输入命令java检测安装是成功ps：%SystemRoot%\system32;%SystemRoot%;%SystemRoot%\System32\Wbem;环境变量原本的文件内容表示的dos系统下cmd的解释器，在环境变量配置时，定义的环境变量文件名不区分大小写path=PATH。eclipse：eclipse下载地址选择的下载版本为一个zip而不是官网的exe文件，官网的文件还需要后续联网下载，网络不稳定容易失败，zip文件解压缩之后既可以使用。python插件：1.打开eclipse——Help——add-PyDev-http://pydev.org/updates——PyDev——PyDev for eclipse——下一步——重启——建立Python工程上述过程同样需要上境外网络，连接VPN实施。或者参考：2.python插件下载地址pyDev包下载地址下载PyDev 4.1.0.zip包，把压缩包里面的plugins中的文件解压到Eclipse安装目录下plugins文件夹中，压缩包里面features中的文件目录也是同样操作。之后重启Eclipse。检查是否已经正确安装pydev：打开Eclipse–&gt;Windows–&gt;preferences就能找到Pydev。配置解释器。官网下载Python27或者Python34选择Window &gt; Preferences &gt; Pydev &gt; Python Interpreter&gt;New ，继续配置解释器：Python安装在F:\Python27 路径下。单击 New，进入对话框。Interpreter Name可以随便命名，Interpreter Executable选择Python解释器python.exe，在安装文件夹下查找。而后下一步下一步。建立Python工程：工程建立：file-new-project-PyDev-PyDev Project-命名-finish文件建立：项目名右键-new-PyDev Module（.py文件）-编写-运行Python Run]]></content>
      <categories>
        <category>笔记</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown编辑器]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F13%2FMarkdown%E7%BC%96%E8%BE%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[##MaHua是什么?一个在线编辑markdown文档的编辑器 向Mac下优秀的markdown编辑器mou致敬 ##MaHua有哪些功能？ 方便的导入导出功能 直接把一个markdown的文本文件拖放到当前这个页面就可以了 导出为一个html格式的文件，样式一点也不会丢失 编辑和预览同步滚动，所见即所得（右上角设置） VIM快捷键支持，方便vim党们快速的操作 （右上角设置） 强大的自定义CSS功能，方便定制自己的展示 有数量也有质量的主题,编辑器和预览区域 完美兼容Github的markdown语法 预览区域代码高亮 所有选项自动记忆 ##有问题反馈在使用中有任何问题，欢迎反馈给作者，可以用以下联系方式跟作者交流 邮件(dev.hubo#gmail.com, 把#换成@) QQ: 287759234 weibo: @草依山 twitter: @ihubo ##捐助开发者在兴趣的驱动下,写一个免费的东西，有欣喜，也还有汗水，希望你喜欢该作者的作品，同时也能支持一下。当然，有钱捧个钱场（右上角的爱心标志，支持支付宝和PayPal捐助），没钱捧个人场，谢谢各位。 ##感激感谢以下的项目,排名不分先后 mou ace jquery ##关于作者 123def __init__(self): self.name=[] self.age=[] #该文可以用来便于查看markdown的语法规则感谢作者]]></content>
      <categories>
        <category>博客</category>
        <category>Markdown</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Markdown</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图dfs输出全排序]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F13%2F%E5%9B%BEdfs%E8%BE%93%E5%87%BA%E5%85%A8%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[问题: 生成1~n的排列思路: 穷举所有可能 在生成结果数组前把重复的去掉探索到某一步发现原先选择达不到目标, 就退回一步重新选择.效率比普通DFS高. 可以优化排列数和素数环的程序两种代码一种没有加入回溯，一种有——-分隔 1234567891011121314#coding：utf-8A = [None for i in range(10)]N = 3def dfs(cur): if cur == N: print(A[:N]) else: for i in range(1, N+1): if i not in A[:cur]: A[cur] = i dfs(cur+1)dfs(0) 12345678910111213141516A = [None for i in range(0, 10)]V = [False for i in range(0, 10)]N = 4def dfs(cur): if cur == N: #边界条件到N的时候需要输出结果 print(A[:N]) else: for i in range(1, N+1): #遍历所有的情况 if not V[i]: #V为标志，到排序的这个位置上没有数据时候，进入下一步 V[i] = True #首先改变标志位为true，输入需要排入的数值 A[cur] = i dfs(cur+1) #继续往下搜索 V[i] = False #跳出了循环，需要回溯到进入循环之前的状态dfs(0) 问题: 数字1~n围成一个n个节点的环, 不允许数字重复, 任意2个相邻数字相加, 结果均为素数, 打印所有素数环的组合.思路: 同排列数, 多了素数判断. 123456789101112131415161718192021A = [None for i in range(0, 10)]N = 6def is_prime(n): for i in range(2, n//2+1): if n%i == 0: return False return Truedef dfs(cur): if cur == N: if is_prime(A[0]+A[N-1]): print(A[:N]) else: for i in range(1, N+1): if i not in A[:cur]: if cur == 0 or is_prime(i+A[cur-1]): A[cur] = i dfs(cur+1)dfs(0) 1234567891011121314151617181920212223A = [None for i in range(0, 10)]V = [False for i in range(0, 10)]N = 6def is_prime(n): for i in range(2, n//2+1): if n%i == 0: return False return Truedef dfs(cur): if cur == N: if is_prime(A[0]+A[N-1]): print(A[:N]) else: for i in range(1, N+1): if not V[i]: if cur == 0 or is_prime(i+A[cur-1]): V[i] = True A[cur] = i dfs(cur+1) V[i] = Falsedfs(0)]]></content>
      <categories>
        <category>code</category>
        <category>dfs</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>dfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图dfs水池个数问题]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F13%2F%E5%9B%BEdfs%E6%B0%B4%E6%B1%A0%E4%B8%AA%E6%95%B0%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[输入：第一行输入一个整数N，表示共有N组测试数据每一组数据都是先输入该地图的行数m(0&lt;m&lt;100)与列数n(0&lt;n&lt;100)，然后，输入接下来的m行每行输入n个数，表示此处有水还是没水（1表示此处是水池，0表示此处是地面）输出：输出该地图中水池的个数。要注意，每个水池的旁边（上下左右四个位置）如果还是水池的话的话，它们可以看做是同一个水池。 python代码，一直跑不出递归，已经醉了1234567891011121314151617181920212223242526272829#coding:utf-8import sys sys.setrecursionlimit(1000000000)def dfs(i,j): if (i&lt;0 or i&gt;=m or j&lt;0 or j&gt;=n or (s[i][j]==0)): return s[i][j]==0 dfs(i,j+1) dfs(i,j-1) dfs(i-1,j) dfs(i+1,j)if __name__ == '__main__': #N=raw_input().split() try: s=[] ans=0 m,n=[int(i) for i in raw_input().split()] for i in range(m): s.append([int(i) for i in raw_input().split()]) for i in range(m): for j in range(n): if s[i][j]==1: dfs(i,j) ans +=1 print(ans) print s except: pass 1234567891011121314151617181920212223242526272829303132333435363738394041424344 //C++代码： #include&lt;stdio.h&gt;#include&lt;string.h&gt;int s[101][101],n,m;void dfs(int i,int j)&#123; if(i&lt;0||i&gt;m||j&lt;0||j&gt;n||s[i][j]==0)//当所有的点为0时说明这是一个水池 return; s[i][j]=0;//每次搜索一个点后，置为0，避免重复 //从此点开始往四周扩展 dfs(i,j+1); dfs(i,j-1); dfs(i-1,j); dfs(i+1,j);&#125;int main()&#123; int N; scanf("%d",&amp;N); while(N--) &#123; int i,j,ans=0; memset(s,0,sizeof(s));//初始化，0表示地面，1表示水池 scanf("%d%d",&amp;m,&amp;n); for(i=0;i&lt;m;i++) &#123; for(j=0;j&lt;n;j++) scanf("%d",&amp;s[i][j]); &#125; for(i=0;i&lt;m;i++) &#123; for(j=0;j&lt;n;j++) &#123; if(s[i][j]==1)//每次从是水池的地方开始深搜 &#123; dfs(i,j); ans++; //搜索结束后既为满足条件 &#125; &#125; &#125; printf("%d\n",ans);//输出结果 &#125; return 0;&#125;]]></content>
      <categories>
        <category>code</category>
        <category>dfs</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>dfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[图BFS最小转机问题]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F12%2F%E5%9B%BEBFS%E6%9C%80%E5%B0%8F%E8%BD%AC%E6%9C%BA%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[思路：我们假设所有边的长度都是1，每一个线段表示一个转机，求最少转机就是求最短路径而已深度优先和广度优先的方法都可以，但是广度优先更适合所有边的权重一样的情况输入：第一行n,m,p,q分别为站点个数，航线个数，起始点，目的地后面m行表示m条航线输出：最小转机数量样例：5 7 1 51 21 32 32 43 43 54 5 2 123456789101112#coding:utf-8def change(n,line): #存储图的关系与标记数组 e=[[99999 for i in range(n+1)] for j in range(n+1)] #初始化所有的线路都为最大值99999 for i in range(1,n+1): e[i][i]=0 #自己和自己之间没有线路 for i in range(len(line)): #根据m行输入，确定哪一些节点之间是有航线的， a,b=line[i] a=int(a) b=int(b) e[a][b]=1 #节点之间有航班即为往返都可通行，即为双向图 e[b][a]=1 return e 12345678910111213141516171819def bfs(n,m,p,q,e): head=1 tail=1 que=[[0,0] for i in range(m)] que[tail]=[p,0] tail +=1 book=[0 for i in range(m)] book.insert(p,1) while head&lt;=tail: print ('que=',que) cur=que[head][0] #que队列中首航班号 for i in range(1,n+1): if e[cur][i]==1 and book[i]==0: #利用方向图，从城市cur到城市i是否有航班并且判断城市i是否在队列中 que[tail]=[i,que[head][1]+1] #满足条件，cur到城市i有航班并且城市i不在队列中，则i入队，转机次数+1 tail +=1 book[i]=1 #改变标记，以防重用 if tail==q+1: return(que[tail-1][1]) #由于tail是指向队列队尾的下一个位置，所以减1 head +=1 12345678910111213def main(): n,m,p,q=[int(i) for i in raw_input().split()] line=[] for i in range(int(m)): line.append(raw_input().split()) e=[] print (line) e=change(n,line) print(e) ans=bfs(n,m,p,q,e) print(ans)main()]]></content>
      <categories>
        <category>code</category>
        <category>bfs</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>bfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法集合]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F12%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[冒泡算法：比较相邻的元素。如果第一个比第二个大，就交换他们两个。对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。在这一点，最后的元素应该会是最大的数。针对所有的元素重复以上的步骤，除了最后一个。持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。可以利用冒泡算法的案例：输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有的奇数位于数组的前半部分，所有的偶数位于位于数组的后半部分，并保证奇数和奇数，偶数和偶数之间的相对位置不变。遇到偶数在前奇数在后的情况交换两者的位置。123456789#coding:utf-8def bubble(num,n): for i in range(n): for j in range(n-i-1): if num[j]&gt;num[j+1]: tmp=num[j] num[j]=num[j+1] num[j+1]=tmp return (num) 选择算法：每次讲min置成无序组起始位置元素下标例遍无序组找到最小的如果最小元素不是无序组起始位置元素，则与起始元素交换位置1234567891011def selectsort(num,n): for i in range(n): min=i for j in range(i,n): if num[j]&lt;num[min]: min=j if min!=i: tmp=num[i] num[i]=num[min] num[min]=tmp return (num) 插入算法：插入排序原理很简单，讲一组数据分成两组，我分别将其称为有序组与待插入组。每次从待插入组中取出一个元素，与有序组的元素进行比较，并找到合适的位置，将该元素插到有序组当中。就这样，每次插入一个元素，有序组增加，待插入组减少。直到待插入组元素个数为0。当然，插入过程中涉及到了元素的移动。123456789def insertsort(num,n): for i in range(1,n): tmp=num[i] j=i-1 while j&gt;0 and tmp&lt;num[j]: num[j+1]=num[j] j -=1 num[j+1]=tmp return (num) 快速排序：基本思想是：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。一趟快速排序的算法是： 1）设置两个变量i、j，排序开始的时候：i=0，j=N-1； 2）以第一个数组元素作为关键数据，赋值给key，即key=A[0]； 3）从j开始向前搜索，即由后开始向前搜索(j–)，找到第一个小于key的值A[j]，将A[j]和A[i]互换； 4）从i开始向后搜索，即由前开始向后搜索(i++)，找到第一个大于key的A[i]，将A[i]和A[j]互换； 5）重复第3、4步，直到i=j； (3,4步中，没找到符合条件的值，即3中A[j]不小于key,4中A[i]不大于key的时候改变j、i的值，使得j=j-1，i=i+1，直至找到为止。找到符合条件的值，进行交换的时候i， j指针位置不变。另外，i==j这一过程一定正好是i+或j-完成的时候，此时令循环结束）。12345678910111213141516def quicksort(L, low, high): i = low j = high if i &gt;= j: return L key = L[i] while i &lt; j: while i &lt; j and L[j] &gt;= key: j = j-1 L[i] = L[j] while i &lt; j and L[i] &lt;= key: i = i+1 L[j] = L[i] L[i] = key quicksort(L, low, i-1) quicksort(L, j+1, high) 123456def main(): num=[9,8,7,6,5,4,3,2,1,0] print(bubble(num,10)) print(selectsort(num,10)) print(insertsort(num,10))main()]]></content>
      <categories>
        <category>code</category>
        <category>sort</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四七层模型协议比较]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F12%2F%E5%9B%9B%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B%E5%8D%8F%E8%AE%AE%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[OSI (Open System Interconnection)开放式系统互联参考模型。从下到上七层模型功能及其代表协议： 物理层(Physical) ：规定了激活、维持、关闭通信端点之间的机械特性、电气特性、功能特性以及过程特性。该层为上层协议提供了一个传输数据的物理媒体。Bit，比特。典型协议代表：EIA/TIA-232, EIA/TIA-499, V.35, V.24, RJ45, Ethernet, IEEE 802.3x(以太网) 物理层, FDDI(Fiber Distributed Data Interface, 光纤分布式数据接口) 物理层 数据链路层(Data Link) : 在不可靠的物理介质上提供可靠的传输。该层的作用包括：物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。Frame，帧。典型协议代表：SDLC(Synchronous DataLink Control，同步数据链路控制), HDLC(High-Level Data Link Control, 高级数据链路控制), PPP(Point-to-Point 点到点), IEEE 802.3x 数据链路层, FDDI 数据链路层, ATM(Asynchronous Transfer Mode, 异步传输模式), IEEE 802.5(令牌环) , Frame Relay(帧中继) 网络层(Network) : 负责对子网间的数据包进行路由选择。此外，网络层还可以实现拥塞控制、网际互连等功能。 Packet，包。典型协议代表：IP, ICMP, IGMP, IPX, BGP, OSPF, RIP, IGRP, EIGRP, ARP, RARP, X.25 传输层(Transport) : 传输层是第一个端到端，即主机到主机的层次。传输层负责将上层数据分段并提供端到端的、可靠的或不可靠的传输。此外，传输层还要处理端到端的差错控制和流量控制问题。 Segment，段。典型协议代表：TCP, UDP, TLS, RTP, SCTP, SPX, ATP, IL 会话层(Session) : 管理主机之间的会话进程，即负责建立、管理、终止进程之间的会话。会话层还利用在数据中插入校验点来实现数据的同步。典型协议代表：RPC, SQL, NFS, NetBIOS, SCP, ASP, SSH, Winsock, BSD sockets 表示层(Presentation) : 对上层数据或信息进行变换以保证一个主机应用层信息可以被另一个主机的应用程序理解。表示层的数据转换包括数据的加密、压缩、格式转换等。典型协议代表：TIFF, GIF, JPEG, PICT, ASCII, EBCDIC, encryption, MPEG, MIDI, HTML 应用层(Application) : 为操作系统或网络应用程序提供访问网络服务的接口。典型协议代表：FTP, WWW, Telnet, NFS, SMTP, Gateway, SNMP, HTTP, Whois, SSHOSI 七层模型各层设备：物理层：各种传输媒体(光线，网线)，各类 DTE 和 DCE 之间通讯的物理设备(计算机， HUB)，各类插槽，插座数据链路层：两个子层：LLC(Logical Link Control, 逻辑链路控制层)，MAC(Media Access Control，媒体访问控制层)。网卡，网桥和二层交换机网路层：路由器，网关和三层交换机传输层：四层交换机会话层：五层交换机表示层：六层交换机应用层：计算机，负载均衡和七成交换机 TCP/IP网络协议TCP/IP(Transmission Control Protocol/Internet Protocol，传输控制协议/网间网协议)是目前世界上应用最为广泛的协议，它的流行与 Internet 的迅猛发展密切相关。TCP/IP 最初是为互联网的原型 ARPANET 所设计的，目的是提供一整套方便实用、能应用于多种网络上的协议，事实证明 TCP/IP 做到了这一点，它使网络互联变得容易起来，并且使越来越多的网络加入其中，成为 Internet 的事实标准。TCP/IP 参考模型分为四个层次： 主机到网络层:实际上TCP/IP参考模型没有真正描述这一层的实现，只是要求能够提供给其上层-网络互连层一个访问接口，以便在其上传递IP分组。由于这一层次未被定义，所以其具体的实现方法将随着网络类型的不同而不同。 网络互连层：定义了分组格式和协议，即IP协议（Internet Protocol）。网络互连层除了需要完成路由的功能外，也可以完成将不同类型的网络（异构网）互连的任务。除此之外，网络互连层还需要完成拥塞控制的功能。 传输层：使源端主机和目标端主机上的对等实体可以进行会话。在传输层定义了两种服务质量不同的协议。即：传输控制协议TCP（transmission control protocol）和用户数据报协议UDP（user datagram protocol）。TCP协议是一个面向连接的、可靠的协议。它将一台主机发出的字节流无差错地发往互联网上的其他主机。在发送端，它负责把上层传送下来的字节流分成报文段并传递给下层。在接收端，它负责把收到的报文进行重组后递交给上层。TCP协议还要处理端到端的流量控制，以避免缓慢接收的接收方没有足够的缓冲区接收发送方发送的大量数据。 UDP协议是一个不可靠的、无连接协议，主要适用于不需要对报文进行排序和流量控制的场合。 应用层：包括 OSI 参考模型中的会话层和表示层。面向不同的网络应用引入不同的应用层协议。其中，有基于 TCP 协议的，如 FTP(File Transfer Protocol，文件传输协议)， Telnet(虚拟终端协议)， HTTP(Hyper Text Transfer Protocol，超文本链接协议)；基于 UDP 协议的：如 SNMP, TFTP，NTP。 OSI七层协议和TCP/IP四层协议之比较: 分层结构OSI参考模型与TCP/IP协议都采用了分层结构，都是基于独立的协议栈的概念。OSI参考模型有7层，而TCP/IP协议只有 4 层，即 TCP/IP协议没有了表示层和会话层，并且把数据链路层和物理层合并为网络接口层。不过，二者的分层之间有一定的对应关系 标准的特色OSI 参考模型的标准最早是由 ISO 和 CCITT (ITU的前身)制定的，有浓厚的通信背景，因此也打上了深厚的通信系统的特色，比如对服务质量（QoS）、差错率的保证，只考虑了面向连接的服务。并且是先定义一套功能完整的构架，再根据该构架来发展相应的协议与系统。TCP/IP 协议产生于对 Internet 网络的研究与实践中，是应实际需求而产生的，再由 IAB、IETF 等组织标准化，而并不是之前定义一个严谨的框架。而且 TCP/IP 最早是在 UNIX 系统中实现的，考虑了计算机网络的特点，比较适合计算机实现和使用。 连接服务OSI 的网络层基本与 TCP/IP 的网际层对应，二者的功能基本相似，但是寻址方式有较大的区别。OSI的地址空间为不固定的可变长，由选定的地址命名方式决定，最长可达 160byte，可以容纳非常大的网络，因而具有较大的成长空间。根据 OSI 的规定，网络上每个系统至多可以有 256 个通信地址。TCP/IP网络的地址空间为固定的 4byte (在目前常用的 IPv4 中是这样，在 IPv6 中将扩展到 16byte)。网络上的每一个系统至少有一个唯一的地址与之对应。 传输服务OSI 与 TCP/IP 的传输层都对不同的业务采取不同的传输策略。OSI 定义了五个不同层次的服务：TP1，TP2，TP3，TP4，TP5。TCP/I P定义了 TCP 和 UDP 两种协议，分别具有面向连接和面向无连接的性质。其中 TCP 与 OSI 中的 TP4，UDP 与OSI中的 TP0 在构架和功能上大体相同，只是内部细节有一些差异。 应用范围OSI 由于体系比较复杂，而且设计先于实现，有许多设计过于理想，不太方便计算机软件实现，因而完全实现 OSI 参考模型的系统并不多，应用的范围有限。而 TCP/IP 协议最早在计算机系统中实现，在 UNIX、Windows平台中都有稳定的实现，并且提供了简单方便的编程接口 (API)，可以在其上开发出丰富的应用程序，因此得到了广泛的应用。TCP/IP 协议已成为目前网际互联事实上的国际标准和工业标准。]]></content>
      <categories>
        <category>笔记</category>
        <category>网络协议</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>tcp/ip</tag>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AWS简称及基本架构介绍]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F12%2FAWS%E7%AE%80%E7%A7%B0%E5%8F%8A%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[文档教程位置 AWS整体架构 ·VPC：·私有网络AWS 云中逻辑隔离的虚拟网络。从所选的范围内定义 VPC 的 IP 地址空间 对VPC的IP寻CIDR块的控制 为您的VPC CIDR块划分子网的能力 网络访问控制列表 多个IP地址和多个弹性网络接口（ENI）的分配 通过私有连接将VPC和现场IT基础设施连接 ·常见的路由：·路由表的将决定子网的功能 IGW：提供对internet的访问，公有子网带通过IGW实现进/出站internet连接 VGW：提供对数据中心的访问，虚拟专用网关 NAT 网关：一项高度可用的托管网络地址转换 (NAT) 服务，可便于私有子网中的资源访问 Internet，可以在官方AMI上直接启动NAT网关实例，私有子网通过公有子网中运行NAT的Amazon EC2实例实现的出战Internet连接。 VPC对等：与NACL和安全组一起维护VPC的安全，允许在对等VPC之间路由流量，这样两个VPC中的实例可以彼此通信，就像在同一个网络中一样。两个对等的VPC不能具有CIDR块重叠的CIDR块。 ·ELB：·Elastic Load Balancing 弹性负载均衡， 在多个 Amazon EC2 实例之间自动分配应用程序的传入流量，软件负载均衡。 在同一区域可用区实例之间实现均衡 根据用户定义的运行状况检查检测状况欠佳的实例 SSL终端支持自动一证书 ·EC2：·Elastic Compute Cloud 一种 Web 服务，云计算服务平台，用于计算相当于一个虚拟机，可以在云中提供安全并且大小可调的计算容量。该服务旨在让开发人员能够更轻松地进行 Web 规模的云计算。让使用者可以租用云端电脑运行所需应用的系统。类型：C3计算优化、R3内存优化、G2 GPU优化、I2 HS1存储优化 ENI：弹性网络接口，创建的EC2实例具有的虚拟网络接口，具有属性如下：MAC地址、主要私有IP地址，一个或多个次要私有IP地址、每个私有IP地址都有弹性EIP、公有IP地址、安全组、目标检查标记、说明。使用案例：创建管理网络；许可身份验证；在VPC中使用网络和安全性设备 EIP：专为动态云计算设计的静态IP地址，EIP与AWS账号关联，而不是与特定实例关联；而公有IP地址也称为动态IP地址与实例相关。 IGW：整体网关 ALB：Application Load Balancer ALB是位于OSI模型第七层的负载均衡器，因此它能根据网络包的内容将该网络包路由到不同的后端服务。现有的负载均衡器多是位于OSI模型第四层的TCP/UDP均衡器。与这些均衡器不同的是，ALB将检查网络包的内容，并将该网络包发送给适当的服务。当前，ALB支持基于URL对路由流量定义多至十条的独立规则。 Amazon CloudWatch是一项针对 AWS 云资源和在 AWS 上运行的应用程序进行监控的服务。CPU 使用率、数据传输和磁盘使用活动等，弹性负载均衡器、Amazon SQS 队列、Amazon SNS 主题等更多 Amazon CloudFront 是一种全球内容分发网络 (CDN) 服务，用于内容传输，可以安全地以低延迟和高传输速度向浏览者分发数据、视频、应用程序和 API。建或修改现有 AWS CloudFormation 模板。一个描述了您的所有资源及其属性的模板。 Amazon Simple Storage Service (Amazon S3)对象存储，使您能够轻松实用地大规模收集、存储和分析数据，而不管格式如何。S3 是专为从任意位置存储和检索任意大小的数据而构建的对象存储，包括来自网站和移动应用程序、公司应用程序的数据以及来自 IoT 传感器或设备的数据。S3可与CloudFront(CDN)结合使用，可以利用分布式网络给边远地区加速 一个对象的大小可以达到5TB 每个对象存储在存储桶中，通过开发人员分配的唯一密钥进行检索 无限的存储、无限的对象 原生在线HTTP/S访问 通过在同一区域不同可用区间进行复制，持久性 面对Internet的对象存储 Amazon Route 53是一种可用性高、可扩展性强的云域名系统 (DNS) Web 服务，用于DNS域名服务。 IAM：Identity and Access Management“身份识别与访问管理”，身份管理 DMZ英文“demilitarized zone”的缩写，中文名称为“隔离区”，也称“非军事化区”。它是为了解决安装防火墙后外部网络的访问用户不能访问内部网络服务器的问题，而设立的一个非安全系统与安全系统之间的缓冲区。该缓冲区位于企业内部网络和外部网络之间的小网络区域内。在这个小网络区域内可以放置一些必须公开的服务器设施，如企业Web服务器、FTP服务器和论坛等。另一方面，通过这样一个DMZ区域，更加有效地保护了内部网络。因为这种网络部署，比起一般的防火墙方案，对来自外网的攻击者来说又多了一道关卡。 本地存储本地存储适合临时存储不断变化的信息（如缓冲区、缓存、暂存数据和其他临时内容），或者在实例机群内复制的数据。 EBS数据块存储 Elastic Block Store，相当于虚拟机硬盘，最大为1TB。实例依靠虚拟网络连接装载，持久性存储，可以重新附加在其他的EC2实例，利用快照实现，一个EC2实例可以有多个EBS卷，但是多个EC2不能共享卷。应用场景：简单硬盘设备；经常更改数据；对原始、未格式化数据块级别存储的访问权。 EBS快照存储在S3中 RDSAmazon Relational Database Service (Amazon RDS) 是一种可让用户在云中轻松设置、操作和扩展关系数据库的 Web 服务。它在管理耗时的数据库管理任务的同时，提供经济实用的可调容量，使您能够腾出时间专注于应用程序和业务。 RDS 让您能够访问非常熟悉的 MySQL、MariaDB、Oracle、Microsoft SQL Server 或 PostgreSQL 数据库引擎的功能。 AWS Elastic Beanstalk是一项易于使用的服务，用于在熟悉的服务器（例如 Apache 、Nginx、Passenger 和 IIS）上部署和扩展使用 Java、.NET、PHP、Node.js、Python、Ruby、GO 和 Docker 开发的 Web 应用程序和服务。上传代码，Elastic Beanstalk 即可自动处理从容量预置、负载均衡、自动扩展到应用程序运行状况监控的部署。同时，您能够完全控制为应用程序提供支持的 AWS 资源，并可随时访问基础资源。 AWS SQS、SNS、SWF消息发送各个工作流用 Amazon ElastiCache缓存 Amazon Glacier存档，将设置了生命周期规则（如90天）的S3存档，成本极低的存档存储服务，能够提供高耐久性存储，极低成本存储，允许在3-5小时内检索数据。可以利用Storage Gateway进行场外备份 安全性SSL加密型终端节点、AES-256自动加密数据、IAM策略指定账户中的哪些用户有权对特定文件库执行操作 Amazon Simple Email Service电子邮件Auto Scaling自动扩大或缩小Amazon EC2容量；响应需求峰值；当需求下降时，削减不需要的实例以节省费用；根据一天中的时间、按指标或通过API自动扩展 AMI亚马逊系统映像，提供启动实例所需的信息 AWS Direct Connect建立从本地设施到Amazon VPC的专用网络链接，建立AWS和数据中心、办公室或托管环境之间建立私有连接。 MSDNMicrosoft Developer Network用来帮助开发人员使用Microsoft产品和技术]]></content>
      <categories>
        <category>笔记</category>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>AWS</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[article title]]></title>
    <url>%2Fhexoblog%2F2017%2F08%2F12%2Farticle-title%2F</url>
    <content type="text"><![CDATA[Welcome to dclarken’s page!8.12 is my first day for writing!First of all,I want to say thank you to my best friends :Dachang,Hongwei,Jingchang,Xidun,Yue,YunhaoBest wishes to all of you!]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>freinds</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[碎片2]]></title>
    <url>%2Fhexoblog%2F2017%2F05%2F12%2F%E7%A2%8E%E7%89%872%2F</url>
    <content type="text"><![CDATA[雪城云，微山雨，游鱼在水雁在云。 遥遥绵雨寄情愫，此情深深悲千古。 苍云甲，长歌琴，赤甲藏心琴藏影。 坚坚盾护怜疏影，望尽纷纷天涯路。]]></content>
      <categories>
        <category>随笔</category>
        <category>碎片</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>碎片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[碎片1]]></title>
    <url>%2Fhexoblog%2F2017%2F05%2F12%2F%E7%A2%8E%E7%89%871%2F</url>
    <content type="text"><![CDATA[巷陌乍晴，絮飞草上，断线纸鸢醉春风。 香径里少年寻觅，小楼上伊人望空。 素月当空，烛影更阑，傻傻少年思悠悠。 想着明儿把线断，借着由儿再寻楼。]]></content>
      <categories>
        <category>随笔</category>
        <category>碎片</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>碎片</tag>
      </tags>
  </entry>
</search>
